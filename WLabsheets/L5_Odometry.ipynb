{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "L6_Odometry.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "run_control": {
          "read_only": false
        },
        "id": "jKW7W_d3IaEj"
      },
      "source": [
        "# Labsheet 6: Odometry\n",
        "\n",
        "This labsheet investigates using the motor information available in the Webots simulation of an e-puck to implement a simple kinematic model.  This will allow for changes of pose (position and rotation) to be estimated.  Tracking the robot pose will become a valuable source of information for your robot.  You will need an estimate of pose to be able to return to the start location (Go Home).  \n",
        "\n",
        "When we use a Simulator, quite plainly we have access to the exact position of the simulated robot.  In Webots, this is visible in the left hand pane:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_TransRotPanel.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "\n",
        "However, our Simulated robot should not have access to this information.  In reality, it is rare that a robotic system will have easily available and exact information.  Even systems like <a href=\"https://en.wikipedia.org/wiki/Global_Positioning_System\">Global Positionining System</a> can suffer issues such as loss of signal, especially within indoor environments.\n",
        "\n",
        "The information in the left-hand pane is the numerical representation of the robot (i.e., that is the simulation information).  Instead, we will investigate the simulated e-puck robot calculating an estimate of it's own position and rotation (pose).  \n",
        "\n",
        "**Note:** it is important to be aware that simulators often have error added to their numerical representation of a robot and the robots interaction with the environment.  Therefore, you will find whilst working through this labsheet that your Odometry will not be able to achieve a perfect estimate of pose relative to the information available to you as a human user of the simulation.  This is a good reflection of how a mobile robot estimating position with odometry would perform in reality.  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "run_control": {
          "read_only": false
        },
        "id": "pIeySxK5IaEm"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5gWxEEMKL1c"
      },
      "source": [
        "# Overview: Odometry\n",
        "\n",
        "**`Odometry`** refers to maintaining an estimate of position using sensors.  By using a last-known position and a subsequent measurement of change, it is possible to calculate an estimate of the robot position.  This technique is known as **`dead reckoning`**.\n",
        "\n",
        "The real e-puck robot utilises `stepper motors`, and this has been simulated in Webots. `Stepper motors` increment their position by fixed angular quantity. When using `stepper motors` to effect changes of position, they can be conveniently regarded to simultaneously encode rotation.  This is achieved by counting the number of times the `stepper motor` has been commanded to increment by one angular position (i.e. \"counting steps\").  \n",
        "\n",
        "The count of steps is only true when the motor has enough `torque` to effect the rotation - otherwise, the microcontroller will count rotations in software that did not happen in reality.  As such, counting the step commands sent to a stepper motor is `open loop` control.\n",
        "\n",
        "In the previous Labsheet \"Line Following\", you will have developed your first `closed-loop` control system.  Hopefully, your robot was able to follow the line sufficiently well.  This would mean your robot appeared to have an intelligent autonomous behaviour.  It is important to recognise that to achieve this, your robot was utilising a `source of information` from the environment - the line.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"50%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/3PI_InfoSource.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "However, despite the intelligent looking behaviour whilst line following, the robot had no information on how far it had travelled. \n",
        "\n",
        "In this labsheet, we will focus on generating more information for your robotic system to later utilise. In other parts of the line following challenge, relying on line following is no longer sufficient.  For instance:\n",
        "- traversing the gap in the line.\n",
        "- determining the end of the line.\n",
        "- returning to home (start position). \n",
        "\n",
        "If we can utilise the rotary encoders to estimate the robot position, we can use this information to perform operations such as:\n",
        "- turn to a specific angle\n",
        "- move to a specific location\n",
        "- maintain a straight course of travel\n",
        "- estimate the distance travelled\n",
        "- etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5XQTBphPBeJ"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxkga8BEcRDQ"
      },
      "source": [
        "# Kinematics\n",
        "\n",
        "In this section, we will implement a simple kinematic model for the simulated e-puck robot.  This will integrate the contribution of both the left wheel and right wheel to estimate a resultant `pose` of the robot.  In terms of our **`task`**, it would be useful to know:\n",
        "- the X position of the robot in the `task environment`.\n",
        "- the Y position of the robot in the `task environment`.\n",
        "- the rotation of the robot in the `task environment`.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/3PI_KinematicsOverview.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "As the robot travels, we will estimate it's position within a `global co-ordinate frame` annotated $X_{I}$, $Y_{I}$. In our task, it is convenient to set the origin of the `global co-ordinate frame` ($X_{I}=0$, $Y_{I}=0$) when the robot is powered on.  Therefore, where your robot is positioned when it is powered on (or reset) will become the origin of it's subsequent position estimations.\n",
        "\n",
        "Creating a `local co-ordinate frame`, annotated as $X_{R}$, $Y_{R}$, allows us to describe the `configuration` of wheels relative to the robot centre at point $p$.  For our robot, the chassis holds two wheels in a fixed relation (e.g., they are fixed on either side of the robot, and cannot be repositioned).  We assume:\n",
        "- the robot also has wheels of the same size, radius $r$.  \n",
        "- the wheels are configured at a distance $l$ and rotated +/- 90&deg; ($\\pi/2$) respectively from $X_{R}$. This aligns the direction of travel of both wheels with $X_{R}$.  \n",
        "\n",
        "We then address the central question of how the rotation velocity of the left and right wheels, $\\phi_{l}$ and $\\phi_{r}$, will displace the robot within the local frame:\n",
        "\n",
        "> $\\dot{X_{R}} = \\frac{r\\phi_{l}}{2} + \\frac{r\\phi_{r}}{2} $\n",
        "<br> the contribution along $X_{R}$, which we understood as each wheel contributing to half the forward motion of the robot at point $p$. \n",
        "\n",
        "> $\\dot{Y_{R}} = 0$\n",
        "<br> the contribution along $Y_{R}$, which we understood as being zero contribution because the wheels are aligned to $X_{R}$ and unable to slide. \n",
        "\n",
        "> $\\dot{\\theta_{R}} = \\frac{r\\phi_{l}}{2 l} - \\frac{r\\phi_{r}}{2 l}$\n",
        "<br>the contribution of rotation, which we understood to describe the counter-active motion of each wheel, if any, proportional to their distance of separation $2l$.  \n",
        "\n",
        "The above contributions (note, the small dot above the letter indicates they are a contribution) are in the local co-ordinate frame.  Therefore, each component will have a magnitude relative to the local origin.  To utilise these as a displacement in the global co-ordinate frame, they require rotating and translating with respect to the prior pose of the robot.  Rotation is achieved via an `orthogonal rotation matrix` using $\\theta_{I}$.  Because $\\dot{Y_{R}}$ is always 0 in our simple model, the matrix multiplication simplifies to the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"50%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/kinematic_update.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "Including the translation, our update calculation at each time step $t$ is therefore:\n",
        "<br>\n",
        "<p align=\"center\">\n",
        "$X_{I}^{\\;t+1} = X_{I}^{\\;t} + ( \\;\\dot{X_{R}} \\; cos \\; \\theta_{I}^{\\;t}\\; )$\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "$Y_{I}^{\\;t+1} = Y_{I}^{\\;t} + (\\;\\dot{X_{R}}\\; sin \\;\\theta_{I}^{\\;t}\\; )$ \n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "$\\theta_{I}^{\\;t+1} = \\theta_{I}^{\\;t} + \\dot{\\theta_{R}}$\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN57wrjbZl8U"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Oesu0DgtDp"
      },
      "source": [
        "## Exercise 1: E-Puck Dimensions\n",
        "\n",
        "1. Find the dimensions of the simulated e-puck robot.  You should be able to refer to the documentation for either the <a href=\"https://cyberbotics.com/doc/guide/epuck\">simulated e-puck</a> or the <a href=\"http://www.e-puck.org/\">real e-puck</a>.  You will need to find:\n",
        "  - Wheel Radius\n",
        "  - Wheel Separation\n",
        "\n",
        "2. **Validate** the value provided by the motor positions sensors (`wb_distance_sensor_get_value()`).  These have been registered for you within the <a href=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/WebotsWorld/Webots_Labs/Webots_Labs/controllers/labsheet_x/labsheet_x.c\"> `labsheet_x.c` example provided on GitHub</a>.\n",
        "\n",
        "```c\n",
        "// Example code to read wheel rotation.\n",
        "float l = wb_position_sensor_get_value(left_position_sensor);\n",
        "float r = wb_position_sensor_get_value(right_position_sensor);\n",
        "printf(\"Wheel rotation: %f, %f\\n\", l, r );\n",
        "```\n",
        "\n",
        "  - The position sensor for each wheel reports a value in `radians`, an angle relative to a unit circle (a circle of radius 1).  \n",
        "  - **Help:** It is likely that your position sensor for each wheel will initialise with an unusual and unknown initial value. We will take this into account in the next exercise.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEi4wIsW4T1j"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z2MCGfCIRyr"
      },
      "source": [
        "## Exercise 2: Implement Kinematics\n",
        "\n",
        "We will utilise this exercise to introduce the C language construct `struct`, which stands for _structure_.  A struct will allow us to group together a set of variables that are all used in the same context. If you are familiar with C++, Java, Python, or another Object-Oriented langauge, this general concept will be familiar to you.\n",
        "\n",
        "Within the intended learning outcomes of this set of Labsheets, we will continue to use variables set in `global scope` (placed outside of the `main()` thread).  In the future, a `struct` becomes very useful to pass a lot of variables via the use of `pointers`.  If you'd like to know more about using `pointers`, you can talk to a member of the teaching staff.\n",
        "\n",
        "We can declare a `struct` to hold the relevant information we need to keep track of the robot pose:\n",
        "\n",
        "```c\n",
        "struct Kinematics_s {\n",
        "  \n",
        "  // Left wheel\n",
        "  float l_last_angle;  // angular position of wheel in last loop()\n",
        "  float l_delta_angle; // calucated difference in wheel angle.\n",
        "\n",
        "  // Right wheel\n",
        "  float r_last_angle;  // angular position of wheel in last loop()\n",
        "  float r_delta_angle; // calucated difference in wheel angle.\n",
        "\n",
        "  float x;             // Global x position of robot\n",
        "  float y;             // Global y position of robot\n",
        "  float th;            // Global theta rotation of robot.\n",
        "  \n",
        "}; // A semi-colon finishes the definition.\n",
        "\n",
        "```\n",
        "\n",
        "In the above example, the name given to the struct is `Kinematics_s`.  Here, `_s` has been appended to help make the code more readble - later we will see the `_s` and remember we are working with a struct.  You can give a struct a name which is useful and meaningful to you.  \n",
        "\n",
        "Once we have declared the `struct` (what it will contain), we can then proceed to use it similar to a normal variable.  In the below, we create an instance of this new `struct` variable:\n",
        "\n",
        "```c\n",
        "  struct Kinematics_s pose;\n",
        "// ^^^^^^^^^^^^^^^^^  ^^^^\n",
        "//  variable \"type\"   variable name\n",
        "```\n",
        "\n",
        "In the rest of our code, we can then access the `struct` to read a value or assign a value in the following ways:\n",
        "\n",
        "```c\n",
        "// At top of program, in global scope\n",
        "struct Kinematics_s pose;\n",
        "\n",
        "// An example of using \"pose\" within loop\n",
        "void loop() {\n",
        "\n",
        "  // We access variables within a struct using\n",
        "  // the dot operator.  We have to provide the name\n",
        "  // of the struct variable (here, \"pose\"), then a dot\n",
        "  // then the name of the variable we accessing.\n",
        "\n",
        "  // Assigns 0 into pose l_last_angle\n",
        "  pose.l_last_angle = 0;\n",
        "\n",
        "  // Reads pose x, giving result to printf() \n",
        "  printf(\" X = %f\\n\", pose.x );\n",
        "\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "1.  Copy the kinematics struct into your Webots code.  If you are following the recommendations, place the struct declaration and `struct Kinematics_s pose` instance into the `global scope` of your code.\n",
        "\n",
        "2. Ensure that you set the initial values of your `pose` struct variable within `setup()`.\n",
        "  - What should the initial value of `l_last_angle` and `r_last_angle` be?\n",
        "  - What should the initial value of `l_delta_angle` be?\n",
        "  - What should the initial value of `r_delta_angle` be?\n",
        "  - What should `x`, `y`, `th` initial values be?\n",
        "  - **Help**: it is necessary to run a step of the simulator within `setup()` to get the initial rotation of the left and right wheels:\n",
        "\n",
        "```c\n",
        "void setup() {\n",
        "  // Existing setup code...\n",
        "  // ...\n",
        "\n",
        "  // Get initial rotations for the left and \n",
        "  // right wheels\n",
        "  wb_robot_step(TIME_STEP);\n",
        "    \n",
        "  float l = wb_position_sensor_get_value(left_position_sensor);\n",
        "  float r = wb_position_sensor_get_value(right_position_sensor);\n",
        "\n",
        "  // Set initial values for the struct\n",
        "  // ...\n",
        "  // pose.x = ???\n",
        "  // pose.y = ???\n",
        "  // etc...\n",
        "  \n",
        "\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "3. Implement a function to perform the kinematic update for your e-puck robot.  A brief template is provided below:\n",
        "  - To make your code easier to alter, it is recommended that you use either `#define` or global variables to set:\n",
        "    - Wheel Radius\n",
        "    - Wheel Separation\n",
        "    - Decide which order of magnitude of units you are working in, e.g. `mm`, `cm`, or `m`.  Webots uses `m` by default within it's data fields.\n",
        "    - In these labsheets, we assume that the forward direction of travel of the robot is aligned to positive x, with theta = 0.  In Webots, you will find that the e-puck is modelled aligned to negative z in the global coordinate frame. You can decide which global coordinate frame you wish to adopt.\n",
        "    - **Help:** remember to provide a function prototype of your `updateKinematics()` function at the top of your program in global scope.\n",
        "\n",
        "```c\n",
        "void updateKinematics() {\n",
        "\n",
        "  // Get current wheel angular positions\n",
        "\n",
        "  // Use current and last wheel angular positions\n",
        "  // to determine l_delta_angle and r_delta_angle\n",
        "\n",
        "  // Since current value has been used, save the current\n",
        "  // left and right angles into  l_last_angle and \n",
        "  // r_last_angle for the next iteration.\n",
        "\n",
        "  // Apply delta_angle within the kinematic equations provided.\n",
        "  // 1) Work out forward contribution of motion\n",
        "  // 2) Work out theta contribution of rotation\n",
        "\n",
        "  // Update the X, Y and th values.\n",
        "  // You can reference the struct in global scope.\n",
        "  // pose.x  = ????;\n",
        "  // pose.y  = ????;\n",
        "  // pose.th = ????;\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "4. From within `loop()` implement a call to your kinematic update function (`updateKinematics()`, as above).  \n",
        "  - Validate that you are gaining a sensible result from your kinematic equations by using `printf()`.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9SpkuilZi-U"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dekJQSQMSOkj"
      },
      "source": [
        "## Exercise 3: Validate & Evaluate Odometry\n",
        "\n",
        "**Qualitative Validation:** validate that odometry is working as you'd expect by observing the behaviour and performance.\n",
        "1. **Forward Travel:**\n",
        "    - Adapt your program so that your e-puck will travel only forwards at a slow speed.  \n",
        "    - You can use the information in the left panel, under `DEF EPUCK E-puck` to validate that your odometry is estimating position with an acceptable degree of error.  Inspect the field labelled `translation x.xxx y.yyy z.zzz`. The order of magnitude of your units may differ.\n",
        "    - It may be useful to set the robot to start at position X=0, Z=0 in the simulator.\n",
        "    \n",
        "2. **Rotation:**\n",
        "    - Adapt your program so that your e-puck will rotation on the spot slowly.\n",
        "    - You can validate your pose estimation for rotation against the simulator.  Similar to the above, you can set the initial in the left panel, `DEF EPUCK E-puck` rotation to be 0.  You will need to set the field `rotation x.xxx y.yyy z.zzz` y.yyy = 0.00.\n",
        "    - You can also validate your e-puck rotation against the markings set into the floor of the example arena.\n",
        "\n",
        "\n",
        "**Quantitative Evaluation:** Use a repeatable method to collect data on your robot performance.  Use this data to `characterise` (identify) the performance of the odometry and robot.  \n",
        "\n",
        "3. **Forward Travel:** Write some motor operation code so that your robot will drive forwards until it reaches a set distance.  Use your new odometry information to achieve this, e.g:\n",
        "\n",
        "```c\n",
        "void loop() {\n",
        "\n",
        "  // Remember to update pose!\n",
        "  updateKinematics();\n",
        "\n",
        "  // Adapt this criteria depending on your\n",
        "  // implementation.  Units and sign are \n",
        "  // important here.\n",
        "  if( pose.x < 100 ) {\n",
        "      // continue to drive fowards\n",
        "  } else {\n",
        "      // stop.\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        " - Take measurments of your robot's stopping distance.  \n",
        "    - Collect data from two sources: the internal measurement (calculated pose, odometry) and the external reality (`ground truth`, from the Webots Simulator left-hand panel).  If you are working online in Google Colab, use the provided boxplot code below to plot your data. \n",
        "    - Does your robot consistently `overshoot` (stop late), or `undershoot` (stop early)?  \n",
        "    - How is this visible on your boxplot?\n",
        "    - Is this a problem with your motor control, or an error in kinematics, or another source of error?\n",
        "    - In the procedure you have adopted to measure distance, how might you improve the precision and accuracy of your measurements, or your capability to record error?\n",
        "    - How many time steps does it take for your robot to traverse the distance.  How much error is occuring per timestep?\n",
        "    - Does the error you observe change with respect to the commanded wheel speed of the robot? (e.g., travelling the same distance, but at different speeds).\n",
        "    - How many repeated trials (or, collected data points) are necessary to give you a clear indication of the system performance?\n",
        "  - **Hypothesise:** Given the form of the kinematic update equations, which parameter is most likely to effect the performance of the forward ($X_{R}$) contribution?  \n",
        "    - Adjust likely parameters to see if you can improve the performance, and repeat your evaluation.\n",
        "  - **Hypothesise:** When completing this exercise, you may notice that when your motors are both commanded to 0 speed, your odometry still updates with a very small amount of error.  What might be a source of this error?\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "4. **Rotation:** Write some motor operation code so that your robot will rotate on the spot to a specific angle.  \n",
        "  - For this exercise, do not use time to perform a rotation.  Instead, write code to control motors via your global co-ordinate $\\theta$ value.  A good start is to simply stop rotation once a desired angle is achieved (`>= angle`).\n",
        "  - **Evaluate:** Perform similar evaluations as the above.  Take a number of measurements to `characterise` the performance of your robot. \n",
        "    - In the procedure you have adopted to measure distance, how might you improve the precision and accuracy of your measurements, or your capability to record error?\n",
        "  - **Hypothesise:** Make a similar hypothesis on which parameter most effects the $\\theta$ contribution.  Explore parameters to see if you can improve the error when your robot rotates on the spot.\n",
        "\n",
        "\n",
        "\n",
        "5. **Discussion**:  Consider the observations you have made of translation and rotation movement for your robot.\n",
        " - **Hypothesise:** Which of these generates the more significant error in your odometry.  \n",
        "  - discuss possible causes within your robotic system, across environment, hardware, software and task.\n",
        "  - discuss a rationale for whether rotation or translation of the robot has the greater impact on the overall error observed in odometry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "EWGtC8jCRAzd",
        "outputId": "75f7a04d-c68f-4c2d-869b-40446b87a299"
      },
      "source": [
        "#\n",
        "# An example of using Python, Seaborn and\n",
        "# Pandas to plot data into a Boxplot. \n",
        "\n",
        "# We will use a library called Seaborn to \n",
        "# make our box plot for us, so we import it.\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# To graph more than one dataset is a little \n",
        "# complicated.  We need to format the\n",
        "# data into 'dataframes'.  We use the pandas\n",
        "# library to do this for us.  Import pandas:\n",
        "import pandas as pd\n",
        "\n",
        "# Add your measurements into the arrays\n",
        "# like the following.  \n",
        "# Here, these are distance between the\n",
        "# 3Pi+ center and the line center.\n",
        "x_error_initial = [-9.1, -12.4, -8.6, -10.3, -15.4, -11.2, 10.0, -6.0, -8.1, 1.1]  \n",
        "x_error_improved = [-12.2, 10.1, 8.1, -8.2, 0.2, 8.5, -6.4, 6.2, 1.1, 0.8]\n",
        "\n",
        "th_error_initial = [-9.1, -12.4, -8.6, -10.3, -15.4, -11.2, 10.0, -6.0, -8.1, 1.1]  \n",
        "th_error_improved = [-12.2, 10.1, 8.1, -8.2, 0.2, 8.5, -6.4, 6.2, 1.1, 0.8]\n",
        "\n",
        "# You can make further arrays, following the\n",
        "# pattern:\n",
        "# pwm_60 = [ , , , ]\n",
        "\n",
        "# We use the .DataFrame() function to apply a \n",
        "# label to each array of results\n",
        "x_initial_dataframe = pd.DataFrame({'X Initial':x_error_initial})\n",
        "x_improved_dataframe = pd.DataFrame({'X Improved':x_error_improved})\n",
        "\n",
        "th_initial_dataframe = pd.DataFrame({'Theta Initial':th_error_initial})\n",
        "th_improved_dataframe = pd.DataFrame({'Theta Improved':th_error_improved})\n",
        "\n",
        "\n",
        "# We then add the two dataframes together.\n",
        "x_combined = pd.concat([ x_initial_dataframe, x_improved_dataframe], axis=0)\n",
        "\n",
        "th_combined = pd.concat([ th_initial_dataframe, th_improved_dataframe], axis=0)\n",
        "\n",
        "# We can now plot both datasets at the same time.\n",
        "plot_x_error = sns.boxplot(data=x_combined)\n",
        "plot_x_error.set(xlabel =\"Implementation\", ylabel = \"Travel Error (mm)\", title ='Fictional Results')\n",
        "\n",
        "#plot_th_error = sns.boxplot(data=th_combined)\n",
        "#plot_th_error.set(xlabel =\"Implementation\", ylabel = \"Rotation Error (degrees)\", title ='Fictional Results')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, 'Rotation Error (degrees)'),\n",
              " Text(0.5, 0, 'Implementation'),\n",
              " Text(0.5, 1.0, 'Fictional Results')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdG0lEQVR4nO3deZQdVbn+8e9DGwhJGE3EZogtNMiCnxIhTqiIioKGwfGiIIIaoy5UrjNirqJG5DqAAyLGyCUXr6CIICaIiCKgwIUEIwFkaCAg2ECAG5J0Qwyd9/dH7SYnXT1UQ+rU6XOez1q1uub9nsMhb+3atXcpIjAzM6u1SdUBmJlZ43FyMDOzHCcHMzPLcXIwM7McJwczM8txcjAzsxwnBxuzJK2WtPPTOO5ISZeWEdOAcs6SNKfscoqStL+k+6qOw8YGJwdreJKWSXo8JYP+afuImBQRd41wbIekkPSs/nUR8T8R8cbyIx82rmMk9aXPslLS3yQdXOcYlkk6oJ5l2tjh5GBjxSEpGfRP/6w6oI3gmoiYBGwNnA6cK2nrimMyA5wcbAxLNYLONL+5pG9LukfSY5L+LGlz4Mq0+4p0lf6KdNX+55rz7Cvp+nTc9ZL2rdn2J0lflfQXSaskXSppcs328yQ9kI69UtKeo/0cEbEOOBuYCOyazruZpG9JulfSg5LOSJ8HSZMlLZC0QtKjkq6StMnA7yQtD3prS9LZwFTgN+l7+ayk8ZJ+KumRdO7rJW032s9jzcHJwZrFt4B9gH2BbYHPAuuA/dL2rVON45ragyRtCywEvgc8GzgFWCjp2TW7HQG8D3gOsCnw6ZptvyX7B/05wA3A/4w2cElt6fxrgXvS6pOB3YBpQCewA/DFtO1TwH3AFGA74ARgVOPgRMRRwL2sr5F9Azga2ArYiey7+DDw+Gg/jzUHJwcbKy5MV7MrJF1YuyFdNb8fOC4i7o+Ivoi4OiLWFDjvDOCOiDg7Ip6MiHOAW4FDavb5r4i4PSIeB35B9g82ABFxZkSsSmWdCOwlaauCn+nlklYAT5Alt/dExEOSBMwCPhERj0bEKuAk4F3puLVAO/C8iFgbEVfFxhkkbS1ZUuhM3+HiiFi5Ec5rY5CTg40Vb4mIrdP0lgHbJgPjgTufxnm3Z/3Ver97yK7U+z1QM98LTILsil/SyZLulLQSWFYTTxHXRsTWwDbARcCr0/opwARgcX9CBC5J6wG+CXQBl0q6S9LxBcsbydnA78jaPv4p6RuSxm2kc9sY4+RgzeBhsqvvXQbZNtIV9T+B5w1YNxW4v0C5RwCHAQeQ3Y7pSOtV4NinRMRq4CPAUZJeTPZ5Hgf2rEmIW6XGa1JN5VMRsTNwKPBJSa9Pp+slSyz9njtc0QPiWBsRX46IPchuzx0MvHc0n8Wah5ODjXmpQfdM4BRJ26cr+ldI2gxYTtb2MFR/iIuB3SQdIelZkg4H9gAWFCh6C2AN8AjZP8gnPYPP8CgwD/hi+jw/Bk6V9BwASTtIOjDNHyypM91+egzoS58RYAlwRPoODgJeM0yxD1LzvUh6raQXpjaQlWS3mdYNdbA1NycHaxafBpYC1wOPAv8JbBIRvcDXgL+kWzQvrz0oIh4hu0L+FNk/8p8FDo6IhwuU+d9kt6DuB24Brn2Gn+E7wJslvQj4HNmto2vTLavLgBek/XZNy6uBa4DTI+LytO04svaSFcCRwAbtMwN8HZidvpdPk9UyfkmWGP4OXEF2q8lakPyyHzMzG8g1BzMzy3FyMDOzHCcHMzPLcXIwM7OcZ428S+ObPHlydHR0VB2GmdmYsnjx4ocjYspg25oiOXR0dLBo0aKqwzAzG1MkDRwd4Cm+rWRmZjlODmZmluPkYGZmOU4OZmaW4+RgZmY5Tg62ga6uLmbMmEFXV1fVoZhZhSpNDpLOlPSQpJtq1m0r6feS7kh/t6kyxlYzZ84cenp6mDMn99phM2shVfdzOAs4jWzo437HA3+IiJPTG66OJxu+2ErW1dXFsmXLAFi2bBldXV10dnYOf5C1hJkzZ9Ld3V1pDL29vQBMmDBhhD3L197ezrx586oOo1SV1hwi4kqysfdrHQbMT/PzgYGvhLSSDKwtuPZgjSQi8CsG6qfqmsNgtouI/kuUB4DtBttJ0iyyl7AzderUOoXW3PprDUMtW+tqhKvkGTNmALBw4cKKI2kNDd0gHdllwqCXChExNyKmR8T0KVMGHRrERmng+FQer8qsdTVicnhQUjtA+vtQxfG0jNmzZw+7bGatoxGTw0XA0Wn+aODXFcbSUjo7O5+qLXR0dLgx2qyFVf0o6zlkL0h/gaT7JH0AOBl4g6Q7gAPSstXJ7NmzmThxomsNZi2u0gbpiHj3EJteX9dA7CmdnZ1u8DOzhrytZGZmFXNyMDOzHCcHMzPLcXIwM7McJwczM8txcjAzsxwnBzMzy3FyMDOzHCcHMzPLcXIwM7McJwczM8tpxJf9mFnSCK/nbBQ9PT3A+pf+tLqyX1Xq5GDWwLq7u4k1q5g6qa/qUCp39yZtAOw0bkXFkVTv3tVtlH3N4ORg1uCmTurjhL1XVh2GNZCTbtiSf6wttwy3OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlNOzLfiQtA1YBfcCTETG92ojMzFpHwyaH5LUR8XDVQZiZtRrfVjIzs5xGTg4BXCppsaRZAzdKmiVpkaRFy5cvryA8M7PmVSg5SNpG0p6SdpZUr4TyqojYG3gTcKyk/Wo3RsTciJgeEdOnTJlSp5DMzFrDkG0OkrYCjgXeDWwKLAfGA9tJuhY4PSIuLyuwiLg//X1I0gXAS4EryyrPzMzWG65B+pfAfwOvjogVtRsk7QMcJWnniPjJxg5K0kRgk4hYlebfCHxlY5djZmaDGzI5RMQbhtm2GFhcSkSZ7YALJEEW488i4pISyzMzsxojPsoq6ZXAkojokfQeYG/guxFxT1lBRcRdwF5lnd/MzIZXpHH5h0CvpL2ATwF3kt1uMjOzJlUkOTwZEQEcBpwWET8Atig3LDMzq1KRHtKrJH0eOAp4dXqUdVy5YZmZWZWK1BwOB9YA74+IB4AdgW+WGpWZmVVqxOSQEsL5wGZp1cPABWUGZWZm1RoxOUj6IFmfhx+lVTsAF5YZlJmZVavIbaVjgVcCKwEi4g7gOWUGZWZm1SqSHNZExL/6FyQ9i2xQPDMza1JFksMVkk4ANpf0BuA84DflhmVmZlUqkhyOJxt0bynwIeBiYHaZQZmZWbVG7OcQEesk/RS4MiJuq0NMZmZWsSJPKx0KLAEuScvTJF1UdmBmZladIreVvkT2LoUVABGxBHh+mUGZmVm1iiSHtRHx2IB1flrJzKyJFRlb6WZJRwBtknYFPg5cXW5YZmZWpSI1h48Be5KNr/Qz4DHg38sMyszMqjVszUFSG7AwIl4LfKE+IZmZWdWGrTlERB+wTtJWdYrHzMwaQJE2h9XAUkm/B3r6V0bEx0uLyszMKlUkOfwqTWZm1iKK9JCeX49ArDF0dXVx3HHH8d3vfpfOzs6qwzGzihTpIb1U0o0DpqsknSrp2fUI0upnzpw59PT0MGfOnKpDMbMKFbmt9Fugj+wxVoB3AROAB4CzgENKiczqrquri2XLlgGwbNkyurq6XHswa1FF+jkcEBGfj4ilafoC8JqI+E+go9zwrJ4G1hZcezBrXUVqDm2SXhoR1wFIegnQlrY9WVpkVnf9tYahlq3+ent7uT2exYeu2KbqUKyBrOkTod5SyyiSHGYCZ0qalJZXATMlTQS+XlpkVncdHR0bJISOjo7KYjGzahV5Wul64IX9HeEGDML3i7ICs/qbPXs2M2fO3GDZqjVhwgR2GreCE/ZeWXUo1kBOumFL/rF261LLKPK00naSfgKcGxGPSdpD0gdKjcoq0dnZ+VRtoaOjw43RZi2sSIP0WcDvgO3T8u144L2mNXv2bCZOnOhag1mLK5IcJkfEL4B1ABHxJNmjraWSdJCk2yR1STq+7PIs09nZycKFC11rMGtxRZJDT+rsFgCSXk42bHdp0miwPwDeBOwBvFvSHmWWaWZm6xV5WumTwEXALpL+AkwB3lFqVNlrSbsi4i4ASecChwG3lFyumZlR7GmlGyS9BngBIOC2iFhbclw7AP+oWb4PeFnJZZqZWTJkcpD0tiE27SaJiKh0pFZJs4BZAFOnTq0yFDOzpjNczaF/zKTnAPsCf0zLryV7h3SZyeF+YKea5R3TuqdExFxgLsD06dOjxFjMzFrOkMkhIt4HIOlSYI+I6E7L7WSPt5bpemBXSc8nSwrvAo4ouUwzM0uKNEjv1J8YkgeBUu/jRMSTkj5K1r+iDTgzIm4us0wzM1uvSHL4g6TfAeek5cOBy8oLKRMRFwMXl12OmZnlFXla6aOS3grsl1bNjYgLyg3LzMyqNNzTSoqIAEjJIJcQavcxM7PmMVwP6cslfUzSBu0LkjaV9DpJ84Gjyw3PzMyqMNxtpYOA9wPnpKeGVgCbkyWUS4HvRMRfyw/RzMzqbbhHWZ8ATgdOlzQOmAw8HhEr6hWcmZlVo8jTSqThMrpH3NHMzJpCkVFZzcysxTg5mJlZzrDJQVKbpMvrFYyZmTWGYZNDRPQB6yRtVad4zMysARRpkF4NLJX0e6Cnf2VEfLy0qMzMrFJFksOvKHd4bjMzazBFxlaaL2lTYLe0qh5vgjMzswqNmBwk7Q/MB5aRvSZ0J0lHR8SV5YZmZmZVKXJb6dvAGyPiNgBJu5EN371PmYGZmVl1ivRzGNefGAAi4nZgXHkhmZlZ1YrUHBZLmgf8NC0fCSwqLyQzM6takeTwYeBYoP/R1avIBuQzM7MmNWxykNQG/C0idgdOqU9IZmZWtSI9pG8b+MIfMzNrbkVuK20D3CzpOjbsIX1oaVGZmVmliiSH/yg9CjMzayhF2hx+lNoczMysRbjNwczMctzmYGZmOW5zMDOznCGTg6TdI+LWiLhC0mYRsaZm28vrE56ZmVVhuDaHn9XMXzNgm3tIm5k1seGSg4aYH2zZzMyayHDJIYaYH2zZzMyayHAN0jtK+h5ZLaF/nrS8Q1kBSToR+CCwPK06ISIuLqs8s0Z37+o2Trphy6rDqNzdK9sAeP6WfRVHUr17V7ehzcotY7jk8Jma+YFDdJc9ZPepEfGtksswa3jt7e10d8M//GJe1qzLnqT/x9otKo6ketos+22UacjkEBHzSy3ZzEY0b968qkNoGDNmzABg4cKFFUfSGoq8Ca4KH5V0o6QzJW0z2A6SZklaJGnR8uXLB9vFzMyepkqSg6TLJN00yHQY8ENgF2Aa0E32DuuciJgbEdMjYvqUKVPqGL2ZWfMr0kN6o4uIA4rsJ+nHwIKSwzEzswFGTA6SppA9PdRRu39EvL+MgCS1R0R3WnwrcFMZ5ZiZ2dCK1Bx+Tfbe6MuAejxD9g1J08j6UiwDPlSHMs3MrEaR5DAhIj5XeiRJRBxVr7LMzGxwRRqkF0h6c+mRmJlZwyhSczgOOEHSv4D+rjgREe6yuZHNnDmT7u7ukXcsUW9vLwATJkyoNA7IOvn4OX+zaoyYHCLC3RFbSISHzTKzgo+ySjoU2C8t/iki/HhpCRrhKtm9UM0MCrQ5SDqZ7NbSLWk6TtLXyw7MzMyqU6Tm8GZgWkSsA5A0H/gr8PkyA6unRrjX3yh6erLBzfprEK3O7R7Wqor2kN4aeDTNb1VSLJXp7u5m9RNr6ZuwbdWhVK5tk+xtsI9t4qamtt5HfdFgLatIcvg68FdJl5O9y2E/4PhSo6pA34RteXx3P7Fr621+68WwblXVYZhVosjTSudI+hPwkrTqcxHxQKlRmZlZpYZskJa0e/q7N9AO3Jem7dM6MzNrUsPVHD4JzGLwIbMDeF0pEZmZWeWGexPcrDT7poh4onabpPGlRmVmZpUqMrbS1QXXmZlZkxiy5iDpucAOwOaSXkz2pBLAlkD1A++YmVlphmtzOBA4BtgROKVm/SrghBJjMjOzig3X5jAfmC/p7RFxfh1jMjOzihXp53C+pBnAnsD4mvVfKTMwMzOrTpGB984ADgc+Rtbu8E7geSXHZWZmFSrytNK+EfFe4P8i4svAK4Ddyg3LzMyqVCQ5PJ7+9kranuxtcO3lhWRmZlUrMvDeAklbA98EbiDrHe0xjM3MmliR5PCNiFgDnC9pAVmj9BMjHGNmZmNYkdtK1/TPRMSaiHisdp2ZmTUf95AGent7aYteJt1wdtWhWCPpe5JejbybWTNyD2kzM8txD2lgwoQJPLbJFn4TnG1g81svZpLfBGctqkibwx8knSJpUZq+Lanp3iNtZmbrFUkOPyG7lfRvaVoJ/FeZQZmZWbWKPMq6S0S8vWb5y5KWlBWQmZlVr1APaUmv6l+Q9ErW95o2M7MmVCQ5fAT4gaRlku4BTgM+9EwKlfROSTdLWidp+oBtn5fUJek2SQc+k3LMzOzpKTJk9xJgL0lbplU9wLuAG59BuTcBbwN+VLtS0h7p3HsC2wOXSdotIvqeQVlmZjZKQ9YcJG2ZruJPk/QGskbp9wJdZA3TT1tE/D0ibhtk02HAuakn9t2prJc+k7LMzGz0hqs5nA38H9lQGR8EvkDWS/qtqTZRhh2Aa2uW70vrciTNAmYBTJ06taRwzMxa03DJYeeIeCGApHlANzA1IgoNuifpMuC5g2z6QkT8etSRDhARc4G5ANOnT49nej4zM1tvuOSwtn8mIvok3Vc0MaRjDnga8dwP7FSzvGNaZ2ZmdTTc00p7SVqZplXAi/rnJa0sKZ6LgHdJ2kzS84FdgetKKsvMzIYw3NhKbWUVKumtwPeBKcBCSUsi4sCIuFnSL4BbgCeBY/2kkplZ/RXpIb3RRcQFwAVDbPsa8LX6RmRmZrWKdIIzM7MWU0nNoRG19T7K5rdeXHUYlWvreRiAvomTK46kem29j8L4cVWHYVYJJwegvb2d7u5u8Nj99Kx7EoCt/F3A+HG0t7dXHYVZJZwcgHnz5lUdQsOYMWMGAAsXLqw4EjOrktsczMwsx8nBzMxynBzMzCzHycHMzHKcHMzMLMfJwczMcvwoq5mNaObMmVlfoAr19PQA6x+3rlJ7e3vTPwLv5GBmY4KkqkNoKU4OZjaiZr9Ktjy3OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVlOJclB0jsl3SxpnaTpNes7JD0uaUmazqgiPjOzVlfVa0JvAt4G/GiQbXdGxLQ6x2NmZjUqSQ4R8XfwC8PNzBpVI7Y5PF/SXyVdIenVQ+0kaZakRZIWLV++vJ7xmZk1vdJqDpIuA547yKYvRMSvhzisG5gaEY9I2ge4UNKeEbFy4I4RMReYCzB9+vTYWHGbmVmJySEiDngax6wB1qT5xZLuBHYDFm3k8BrSzJkz6e7urjSGnp4eAGbMmFFpHADt7e3Mmzev6jDMWlJD3VaSNEVSW5rfGdgVuKvaqFqLJLcFmVk1DdKS3gp8H5gCLJS0JCIOBPYDviJpLbAO+HBEPFpFjFXwVbKZNYqqnla6ALhgkPXnA+fXPyIzM6vVULeVzMysMTg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Shi7A9LJGk5cE/VcTSRycDDVQdhNgj/Njeu50XElME2NEVysI1L0qKImD7ynmb15d9m/fi2kpmZ5Tg5mJlZjpODDWZu1QGYDcG/zTpxm4OZmeW45mBmZjlODmZmluPk0MAkPVvSkjQ9IOn+NL9C0i2jPNdbJO0xymOOkXTaCPtsL+mXaX6apDfXbDtU0vHPtAyrr7Hwu2skkvaXtKDqODY2J4cGFhGPRMS0iJgGnAGcmuankb0pbzTeAozqf9KCMf4zIt6RFqcBb67ZdlFEnLyxy7RyjYXf3dMhqZKXm41VTg5jV5ukH0u6WdKlkjYHkLSLpEskLZZ0laTdJe0LHAp8M10B7iLpg5Kul/Q3SedLmjBcYZLOkvQ9SVdLukvSO9L6Dkk3SdoU+ApweCrj8NorQEmHSPpfSX+VdJmk7cr9eqwkVfzufijp2vS721/SmZL+Lumsmv1WSzo1xfUHSVPS+j9J+o6kRcBxkl6ffoNL03k2k3SQpPNqzvVUTUDSGyVdI+kGSedJmpTWHyTpVkk3AG/byN9xQ3ByGLt2BX4QEXsCK4C3p/VzgY9FxD7Ap4HTI+Jq4CLgM+mK8E7gVxHxkojYC/g78IECZbYDrwIOBjaoEUTEv4AvAj9PZfx8wLF/Bl4eES8GzgU+O/qPbA2git/dNsArgE+k850K7Am8UNK0tM9EYFGK6wrgSzXHb5p6Vf8AOAs4PCJeSPaa5I8AlwEvkzQx7X84cK6kycBs4ICI2BtYBHxS0njgx8AhwD7Ac4t8cWONq1lj190RsSTNLwY60lXNvsB5kvr322yI4/+fpDnA1sAk4HcFyrwwItYBtzyNK/8dgZ9Lagc2Be4e5fHWGKr43f0mIkLSUuDBiFgKIOlmoANYQna7q/+C5KfAr2qO71//ghT/7Wl5PnBsRHxH0iXAIan9bAbZxctryG6J/SV9rk2Ba4Dd03nuSHH8FJhV4HOMKU4OY9eamvk+YHOymuCKdH94JGcBb4mIv0k6Bth/lGVqyL0G933glIi4SNL+wImjPN4aQ5W/u3UDyl/H0P+G1Xbg6ilQxrnAR4FHyWogq5RlhN9HxLtrd6yprTQ131ZqIhGxErhb0jsBlNkrbV4FbFGz+xZAt6RxwJEbKYSBZdTaCrg/zR+9kcqzBtAAvzvI/i3rfzDiCLLbmAPdRlbT6UzLR5HdgiL93Rv4IFmiALgWeGX//pImStoNuDWdZ5e03wbJo1k4OTSfI4EPSPobcDNwWFp/LvCZ1Bi3C/AfwP8CfyH7sW8MlwN79DdID9h2Itlth8V4yOVmVOXvDrLawUsl3QS8juzhiA1ExBPA+8h+h0vJah5npG19wALgTekvEbEcOAY4R9KNpFtK6TyzgIWpQfqhjfg5GoaHzzCzMU/S6oiYVHUczcQ1BzMzy3HNwczMclxzMDOzHCcHMzPLcXIwM7McJwdrCpJWb6TzVDbCZhqn6ojR7idpuqTvlRudtRonB7PG0UHWgWtU+0XEooj4eEkxWYtycrCmkq78r5D06zSK58mSjpR0XRqJc5e031mSzpC0SNLtkg4e5FwT08id16VOXIel9cdIulDS7yUtk/RRSZ9M+1wradu0X26k0pqycyPckg1m+OrUifATqYZwVRoR9AZlo5wOtl/tKKLbpthuTLG8KK0/MX2WP6UynUxseBHhydOYn4DV6e/+ZKOFtpMN/nY/8OW07TjgO2n+LOASsgukXYH7gPHp+AVpn5OA96T5rYHbyUb/PAboIhsKYgrwGPDhtN+pwL+n+T8Au6b5lwF/rCn7vFT2HkBXTewLaj7TBGB8mt+VbMyfwfarjfn7wJfS/OuAJWn+RODq9J1MBh4BxlX9381T404eeM+a0fUR0Q0g6U7g0rR+KfDamv1+Edkos3dIuotstM1abwQOlfTptDwemJrmL4+IVcAqSY8Bv6kp40UFRiotMsLtOOC0NNBbH7Bbgc/+KtIw2hHxR2VvddsybVsYEWuANZIeArYjS4pmOU4O1owGjtxZO6pn7W9+YA/QgcsC3h4Rt22wUnpZgTJGGqm0yAi3nwAeBPZK53tiiP2KGjiiqv//tyG5zcFa2TslbZLaIXYmG7Wz1u+Aj6Whm5H04qInjuFHKh3KwBFMtwK6Uw3jKKBtiP1qXUUa7VTZ0OgPp1jMRsXJwVrZvcB1wG/J2gwGXpl/lezWzo3KXizz1VGef6iRSodyI9Cn7BWanwBOB45Ox+/O+vcSDNyv1onAPmkU0ZPx8Oj2NHlsJWtJyt4/vCAifll1LGaNyDUHMzPLcc3BzMxyXHMwM7McJwczM8txcjAzsxwnBzMzy3FyMDOznP8PDluvbG3W0FQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFEtOErkfoVz"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYxx9nuMfmcc"
      },
      "source": [
        "# Basic Path-Planning\n",
        "\n",
        "The final sub-task of the Line Following Challenge is that your robot should:\n",
        "1. recognise the end of the line.\n",
        "2. return to the start position.\n",
        "\n",
        "With kinematics and odometry implemented, it is now possible for the robot to estimate it's pose within the task environment relative to where it started.  The following exercises will help you to implement the necessary code to solve the elements of this problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxVIuzKwgmPb"
      },
      "source": [
        "## Exercise 4: Rotation Maneuver\n",
        "\n",
        "Using your prior work developing a Finite State Machine (FSM), write a new function to complete a rotation maneuver.  We can think of this rotation maneuver to be:\n",
        "> Minimise the error between the `current robot angle` and a `demand angle`.\n",
        "\n",
        "With the simplest approach taken, your solution will likely have a problem when the `demand` and `measurement` sit either side of 0&deg;:\n",
        "\n",
        "```c\n",
        "if( demand_angle > mesurement_angle ) {\n",
        "  // turn left\n",
        "} else {\n",
        "  // turn right\n",
        "}\n",
        "```\n",
        "The above logic stops working effectively across the 0&deg;/360&deg; boundary.  \n",
        "\n",
        "Another way to think about this problem, is that we want to know the **smallest** difference between two angles.  There are infact two differences between two angles, a small way-around, and a large way-around.  Ideally, we would like the robot to take the shortest rotation.  Dealing with a quantity of difference also mitigates the issue of the 0&deg;/360&deg; boundary condition:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"50%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_smallestrotation.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "1. **Hypothesise:** Why might it be preferable that the robot makes the smallest rotation maneuver?\n",
        "\n",
        "2. Give your function a meaningful name, such as `turnToDemandAngle()`.\n",
        "  - Write your function to accept a single argument, `demand angle`.  Your function can make use of the global odometry variable(s).\n",
        "  - This function should either command the motor speeds to effect rotation, or achieve the same functionality within your implementation.\n",
        "  - It may be useful to first of all write some test code to calculate the smallest angle between two angles.  \n",
        "  - Refering to `Labsheet 2 Line Following`, you can implement either:\n",
        "    - a `bang-bang` type method (fixed motor speeds, logical control)\n",
        "    - a `proportional control` method, which uses a `gain` value to determine an appropriate feedback signal to command motor speeds.\n",
        "      -  `measurement` is the current robot rotation angle.\n",
        "      - `demand` is the desired angle of rotation.\n",
        "      - `error signal` is the difference between the `measurement` and `demand`, which we wish to reduce to `0`.\n",
        "  - Use your FSM to call this function until the rotation is complete (i.e. `error signal` = 0).  \n",
        "\n",
        "3. **Validate:** To begin with, it is simplest to start your robot facing at 180&deg; (`pi`), and to set a `demand rotation` of +/- 90&deg; (+/- `pi/2`).  \n",
        "  - To achieve this, you can set the initial value of your odometry to `pi` within your `setup()` function.\n",
        "  - Ensure that your function will operate the correct motor commands to rotate either left or right as appropriate.\n",
        "\n",
        "4. **Validate**: Test your rotation maneuver with different starting rotations and demand rotations.  \n",
        "  - Test for the largest rotation.  The largest rotation your robot will have to make will depend on your implementation.\n",
        "  - Test for boundary conditions, depending on your implementation.  This might include:\n",
        "    - the 0&deg;/360&deg; boundary.\n",
        "    - when the robot faces perfectly in the opposite direction to the demand.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3L4Nmv4ra1J"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brzoikCHn0ml"
      },
      "source": [
        "## Exercise 5: Going Home\n",
        "\n",
        "It is useful to consider a drawing of the final sub-task `Going Home` and the information available to the robot:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_GoingHome.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "There are two common solutions to this task:\n",
        "- **\"One Shot\"**: The robot first rotates to align it's forward direction of travel towards $x=0$, $y=0$.  The robot then drives in a straight line for a fixed distance calculated between the end position to $x=0$, $y=0$.\n",
        "- **\"Iterative\"**: At each timestep, the robot re-calculates the error in rotation between it's it's forward direction of travel towards $x=0$, $y=0$.  At each time step, the robot drives fowards until the distance between the robot's current position and $x=0$, $y=0$ is 0.\n",
        "\n",
        "1. **Hypothesise:** What are the advantages and disadvantages between the `One Shot` and `Iterative` methods?\n",
        "2. It is easiest to first of all implement a `One Shot` method to validate that your robot is able to rotate to face the right direction, and then drive for some distance to $x=0$, $y=0$.\n",
        "3. Update your method to make it `Iterative`.  Similar to line following, it is possible to update the motion of the robot by two independent factors:\n",
        "  - Turning: Whether the robot should adjust motor speeds to effect rotation about it's centre point.  \n",
        "  - Forward: Whether the robot should adjust motor speeds to either travel forwards or come to a stop.\n",
        "  - A convenient approach to this implementation is to extend your function `turnToDemandAngle()` to also include a `foward velocity`.  `Forward velocity` can be changed with respect to a re-calculated distance from the origin $x=0$, $y=0$.\n",
        "  - It is important that your robot can autonomously decide when the task is complete.  If the distance $d$ is calculated between the robot position and $x=0$, $y=0$, what is an acceptable distance to decide the task is complete? \n",
        "    \n",
        "\n",
        "4. **Validate:** Test your `Go Home` functionality against different end-points on the line map.  You can insert a temporary clause into your FSM so that your robot will transition into `Go Home` behaviour when some distance $d$ is calculated from the origin $x=0$, $y=0$.  \n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5-o5ohNZftM"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWgQe8eNTp9j"
      },
      "source": [
        "## Exercise 4: Improve Kinematics\n",
        "\n",
        "For the line following challenge, the simple kinematic model provided is sufficient to enable your robot to travel back to where it started with reasonable performance.  **The exercises in this section can be considered optional or suitable for further work.**  \n",
        "\n",
        "In the simple model detailed in this labsheet, we have worked with the assumption that the robot will move or rotate, exclusively (either one or the other). As such, our model translates by some amount $X_{R}$ and then rotates this translation motion by some $\\theta_{R}$.  These operations are accounted for by the following motor activations:\n",
        "\n",
        "- when left and right motors have equal non-zero velocity and in the same direction, $v_{l} = v_{r} \\ne 0$, the robot will move forwards or backwards in a straight line.\n",
        "- when the left and right motors have equal non-zero and inversed velocity, $v_{l} = -v_{r} \\ne 0$, the robot will rotate on the spot.\n",
        "\n",
        "This presents the exceptional case when the left and right motor are of different velocity, including cases where one my be 0.  Under these conditions, the robot will move on an arc. \n",
        "\n",
        "In our simplified model, we assume that travel on an arc can be sufficiently approximated by the integrating the rotation of the straight line segments generated by $X_{R}$.  \n",
        "\n",
        "When the wheels have differing velocity, the point of rotation for the movement moves away from point $p$.  This new point of rotation is referred to as the `instantaneous centre of rotation` (ICR).  The more similar the wheels speeds, the further the ICR moves from point $p$.\n",
        "\n",
        "\n",
        "1. As a matter of interest:\n",
        "  - **Hypothesise:** If the ICR moves away from point $p$, and so defines an arc of travel for the robot, will the simplified model under-estimate or over-estimate the resultant position in comparison?\n",
        "2. Implement ICR and the kinematic update routine. \n",
        "  - If you need help with this exercise, discuss the matter with the teaching staff. They will help you to decide if you should insatead continue further with labsheets and come back to this later.\n",
        "  - When working on this implementation, be aware of divide-by-zero errors.\n",
        "  - Any gain in performance from this implementation is likely to be more pronounced and visible when you address the full line following challenge, especially the return to home objective.  Therefore, you may need to return to this exercise later.  \n",
        "\n",
        "\n"
      ]
    }
  ]
}