{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L4_ObstacleAvoidance",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNT6X7YHGLUOtDlIsuUaxME",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulodowd/EMATM0053_21_22/blob/main/WLabsheets/L4_ObstacleAvoidance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gawky_WGun5Z"
      },
      "source": [
        "# Labsheet 4: Obstacle Avoidance\n",
        "\n",
        "In previous labsheets we have investigated:\n",
        "- making the robot move.\n",
        "- bang-bang control.\n",
        "- weighted-sensing for line following.\n",
        "- proportional control.\n",
        "- Finite State Machines, transitioning between states or robot behaviours.\n",
        "\n",
        "In this labsheet, we will investigate the new required behaviour Obstacle Avoidance.  This labsheet provides exercises to develop a `reactive` obstacle avoidance controller.  This means that the obstacle avoidance behaviour is created through an immediate response to sensor stimuli, with no memory or planning algorithmically specified.  \n",
        "\n",
        "The principle approach to this obstacle avoidance solution is inspired by Chapter 2 Evolutionary and Neural Techniques from the book:\n",
        "> Nofli, S. and Floreano, D. (2001) _Evolutionary Robotics: The Biology, Intelligence and Technology of Self-organizing Machines._  MIT Press.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zWBXXX4A3nb"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzL0dnt4vJ4u"
      },
      "source": [
        "## E-Puck Proximity Sensors\n",
        "\n",
        "Within the provided Webots world file, your simulated robot should meet an obstruction along the line following map.  This obstruction is a pink block.  The exact location of the pink block is not critical, however it should be investigated by you for the challenge is presents:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_Obstruction.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "Your simulated robot is required to detect this block and safely navigate around it, to rejoin the line and continue line following.  To achieve this functionality, we will use the proximity sensors of the e-puck robot.\n",
        "\n",
        "The simulated e-puck robot has 8 infra-red proximity sensors, positioned around the robot body.  These sensors are enumerated (indexed) following the same scheme in the below diagram (`ps0` ... `ps7`, \"proximity sensor\"):\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/cyberbotics/webots/released/docs/guide/images/robots/epuck/sensors_and_leds.png\">\n",
        "</p>\n",
        "\n",
        "Similar to the ground sensor, the proximity sensor transmits a beam of infra-red light and measures the intensity of the reflection.  These sensors have been modelled in Webots to have the following **`sensor response`**:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"75%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_EpuckProxResponse.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "In the above plot from the <a href=\"https://cyberbotics.com/doc/guide/epuck#e-puck-model\">Webots documentation</a>, we can observe:\n",
        "- the sensor response is `non-linear`.\n",
        "- the sensor response is `high` at `close proximity`.\n",
        "- the sensor response is `low` at `far proximity`.\n",
        "- the maximum range of the sensor is 7cm.\n",
        "- the measured signal flattens out at a value of approximately `34`, an offset bias.\n",
        "- there is some noise in the measurement signal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VugKaszE-0T6"
      },
      "source": [
        "## Exercise 1: E-Puck Model\n",
        "\n",
        "1. If the maximum raw measurement from the `analog-to-digital` converter (ADC) is 4095, how many bits of resolution must the ADC be configured to?\n",
        "\n",
        "2. Would you regard this sensor as:\n",
        "  - `precise`?\n",
        "  - `accurate`?\n",
        "\n",
        "\n",
        "3. **Validate**: Use the Webots simulator and write a simple program to report the readings from the proximity sensors.  Use the below code cell to plot your results with respect to distance.  Does the sensor in Webots perform the same as the graph provided above from the documentation?\n",
        "  - It is easiest to report readings from just one sensor, such as `ps0` or `ps2`.\n",
        "  - You can use the left-hand panel in Webots to set the exact starting position of both the robot and an obstacle.  To identify an obstacle, click the obstacle and then look for the highlighted field in the left-hand pane. \n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_SettingObstacle.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "4. The shape of the `sensor response` is `non-linear`, and this has implications for the robot's ability to perceive the environment:\n",
        "  - What is the useful range of this sensor?\n",
        "  - At what distance, or what reading value, do the sensors become not useful?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "nurDNai1W3JO",
        "outputId": "5f7d99be-ad0c-4c81-b4dc-1dec683bf134"
      },
      "source": [
        "#\n",
        "# An example of using Python, Seaborn and\n",
        "# Pandas to plot data into a line plot with\n",
        "# the region of error around the line.  \n",
        "\n",
        "# We use numpy to create an array of values\n",
        "# Panda dataframes want arrays not lists. \n",
        "import numpy as np\n",
        "\n",
        "# We will use a library called Seaborn to \n",
        "# make our plot for us, so we import it.\n",
        "import seaborn as sns\n",
        "\n",
        "# We need to format the\n",
        "# data into 'dataframes'.  We use the pandas\n",
        "# library to do this for us.  Import pandas:\n",
        "import pandas as pd\n",
        "\n",
        "# Add your measurements into the array\n",
        "# like the following.  \n",
        "# This allows multiple data entries per\n",
        "# point on the x axis.\n",
        "# Columns as:\n",
        "# [ <distance>, <measurement> ]\n",
        "results = np.array( \n",
        "[ [0, 1100],\n",
        "  [0, 1200],\n",
        "  [0, 900],\n",
        "  [0.5, 1100],\n",
        "  [0.5, 1200],\n",
        "  [0.5, 900],\n",
        "  [1, 1100],\n",
        "  [1, 1200],\n",
        "  [1, 900],\n",
        "  [1.5, 1100],\n",
        "  [1.5, 1200],\n",
        "  [1.5, 900],\n",
        "  [2, 1100],\n",
        "  [2, 1200],\n",
        "  [2, 900],\n",
        "  [2.5, 1100],\n",
        "  [2.5, 1200],\n",
        "  [2.5, 900],\n",
        "  [3, 1100],\n",
        "  [3, 1200],\n",
        "  [3, 900],\n",
        "  [3.5, 1100],\n",
        "  [3.5, 1200],\n",
        "  [3.5, 900] # etc\n",
        " ] )\n",
        "\n",
        "# Reformat the data using pandas\n",
        "results = {\"sensor response\": pd.Series(results[:,1], index=results[:,0]) }\n",
        "\n",
        "dataframe = pd.DataFrame( results );\n",
        "\n",
        "\n",
        "# We can now plot both datasets at the same time.\n",
        "# Note, data=combined!\n",
        "plot = sns.relplot(data=dataframe, kind=\"line\")\n",
        "plot.set(xlabel =\"Distance (units?)\", ylabel = \"Sensor ADC Reading\", title ='Fictional Results')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f8d9bc3b2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAFwCAYAAADT+oDMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7gkVX3v//fHAcGIgsKAXOU2aEARcUS849EoKhHjzwvoUVBPiInGWzwJJlFzw4MxenLwGiIENQoSrwRBQH4KHBVhRAQGBUcucRBlBLkIODLD9/xRa0O73bWnZ9jdvWHer+fpZ3evXlX17Ya9P7OqVlWlqpAkSb/tfpMuQJKk+cqQlCSphyEpSVIPQ1KSpB6GpCRJPQxJSZJ6GJIaqSS/TLLzOiz3iiSnj6Kmads5Lsk/jHo7w0qyX5Llk65DUseQ1JxIclWS21soTj22qapNquqKNSy7Y5JKssFUW1V9qqqePfrKZ63r0CSr22e5Ocn3khww5hquSvKscW5T0t0MSc2l32+hOPX4yaQLmgPfqqpNgM2ADwMnJNlswjVJGhNDUiPVRoi7tucPSPK+JFcnuSnJ/03yAODs1v3GNmp7YhvF/d+B9TwpyfltufOTPGngva8n+fsk30hyS5LTk2wx8P5/JPlpW/bsJHus7eeoqjuBTwIPBBa19W6U5J+S/FeSnyX5aPs8JNkiyclJbkxyQ5Jzktxv+nfSXs+4yzfJJ4EdgP9s38ufJ9k4yb8nub6t+/wkW63t55E0HENS4/RPwOOAJwEPBf4cuBN4Wnt/szYC/dbgQkkeCnwZOArYHHg/8OUkmw90eznwamBL4P7A2wbeO5Uu2LYELgA+tbaFJ1nQ1n8HcHVrPhLYDdgL2BXYFnhne+/PgOXAQmAr4C+BtboGZFW9Evgv7h6h/yNwCLApsD3dd/E64Pa1/TyShmNIai59sY1ubkzyxcE32ijqNcCbquqaqlpdVd+sqpVDrPf5wA+r6pNVtaqqjgd+APz+QJ9/q6rLq+p24ES64AKgqo6tqlvatv4GeEySTYf8TPsmuRH4FV3I//equi5JgMOAt1TVDVV1C/Bu4KC23B3A1sDDq+qOqjqn5uZCyXfQheOu7Tv8TlXdPAfrlTQDQ1Jz6YVVtVl7vHDae1sAGwM/Wof1bsPdo7cpV9ON3Kb8dOD5bcAm0I0AkxyZ5EdJbgauGqhnGOdW1WbAQ4CTgKe29oXA7wDfmfqHAfCV1g7wXmAZcHqSK5IcPuT21uSTwGl0x0Z/kuQfk2w4R+uWNI0hqXH5Od1obJcZ3lvTCOsnwMOnte0AXDPEdl8OHAg8i2435Y6tPUMse5eq+iXwx8ArkzyW7vPcDuwx8A+DTdskH9rI9c+qamfgBcBbkzyzre42uoCd8rDZNj2tjjuq6m+rane63dYHAK9am88iaXiGpMaiTXw5Fnh/km3aCO+JSTYCVtAdm+w7n/IUYLckL0+yQZKXAbsDJw+x6QcBK4Hr6YLp3ffgM9wAfAx4Z/s8/wr87yRbAiTZNslz2vMDkuzadsveBKxunxHgQuDl7TvYH3j6LJv9GQPfS5JnJHl0O0Z6M93u1zv7FpZ0zxiSGqe3ARcD5wM3AO8B7ldVtwFHAN9ouy73HVyoqq6nGzH9GV3Y/TlwQFX9fIhtfoJu1+w1wKXAuffwM/wz8LwkewJ/QbdL9dy2K/erwCNav0Xt9S+BbwEfrqqvtffeRHc89UbgFcBvHL+d5n8Bf92+l7fRjTo/SxeQ3wfOotsFK2kE4k2XJUmamSNJSZJ6GJKSJPUwJCVJ6mFISpLUY4M1d7l32n///esrX/nKpMuQdN+zVufY6t7tPjuS/PnPhzk7QJKkfvfZkJQk6Z4yJCVJ6mFISpLUw5CUJKmHISlJUg9DUpKkHoakJEk9DElJknoYkpIk9RhZSCY5Nsl1SS4ZaHtvkh8kuSjJF5JsNvDe25MsS3LZ1N3dW/v+rW1ZksNHVa8kSdONciR5HLD/tLYzgEdV1Z7A5cDbAZLsDhwE7NGW+XCSBUkWAB8CngvsDhzc+kqSNHIjC8mqOhu4YVrb6VW1qr08F9iuPT8QOKGqVlbVlcAyYJ/2WFZVV1TVr4ETWl9JkkZukncBeQ3wmfZ8W7rQnLK8tQH8eFr7E/pWmOQw4DCAHXbYYa2KWXLVDfxy5ao1d5R0n7HJRhuweMeHTroMzWMTCckkfwWsAj41l+utqqOBowEWL15ca7PsL1euYvMHbjSX5Uia566/deWkS9A8N/aQTHIocADwzKqaCrJrgO0Hum3X2pilXZKkkRrrKSBJ9gf+HHhBVd028NZJwEFJNkqyE7AIOA84H1iUZKck96eb3HPSOGuWJK2/RjaSTHI8sB+wRZLlwLvoZrNuBJyRBODcqnpdVS1NciJwKd1u2NdX1eq2njcApwELgGOraumoapYkadDIQrKqDp6h+ZhZ+h8BHDFD+ynAKXNYmiRJQ/GKO5Ik9TAkJUnqYUhKktTDkJQkqYchKUlSD0NSkqQehqQkST0MSUmSehiSkiT1MCQlSephSEqS1MOQlCSphyEpSVIPQ1KSpB6GpCRJPQxJSZJ6GJKSJPUwJCVJ6mFISpLUw5CUJKmHISlJUg9DUpKkHoakJEk9DElJknoYkpIk9TAkJUnqYUhKktTDkJQkqYchKUlSD0NSkqQehqQkST0MSUmSehiSkiT1MCQlSephSEqS1MOQlCSphyEpSVIPQ1KSpB4jC8kkxya5LsklA20vSbI0yZ1JFg+075jk9iQXtsdHB957XJKLkyxLclSSjKpmSZIGjXIkeRyw/7S2S4AXAWfP0P9HVbVXe7xuoP0jwB8Ci9pj+jolSRqJkYVkVZ0N3DCt7ftVddmw60iyNfDgqjq3qgr4BPDCua1UkqSZzadjkjsl+W6Ss5I8tbVtCywf6LO8tc0oyWFJliRZsmLFilHWKklaD8yXkLwW2KGqHgu8Ffh0kgev7Uqq6uiqWlxVixcuXDjnRUqS1i8bTLoAgKpaCaxsz7+T5EfAbsA1wHYDXbdrbZIkjdy8GEkmWZhkQXu+M90EnSuq6lrg5iT7tlmtrwK+NMFSJUnrkVGeAnI88C3gEUmWJ3ltkj9Ishx4IvDlJKe17k8DLkpyIfBZ4HVVNTXp50+AjwHLgB8Bp46qZkmSBo1sd2tVHdzz1hdm6Ps54HM961kCPGoOS5MkaSjzYnerJEnzkSEpSVIPQ1KSpB6GpCRJPQxJSZJ6GJKSJPUwJCVJ6mFISpLUw5CUJKmHISlJUg9DUpKkHoakJEk9DElJknoYkpIk9TAkJUnqYUhKktTDkJQkqYchKUlSD0NSkqQehqQkST0MSUmSehiSkiT1MCQlSephSEqS1MOQlCSphyEpSVIPQ1KSpB6GpCRJPQxJSZJ6GJKSJPUwJCVJ6mFISpLUw5CUJKmHISlJUg9DUpKkHoakJEk9DElJknqMLCSTHJvkuiSXDLS9JMnSJHcmWTyt/9uTLEtyWZLnDLTv39qWJTl8VPVKkjTdBmvqkOSoGZpvApZU1ZdmWfQ44IPAJwbaLgFeBPzLtG3sDhwE7AFsA3w1yW7t7Q8BvwcsB85PclJVXbqmuiVJuqeGGUluDOwF/LA99gS2A16b5J/7Fqqqs4EbprV9v6oum6H7gcAJVbWyqq4ElgH7tMeyqrqiqn4NnND6SpI0cmscSdKF4pOrajVAko8A5wBPAS6eozq2Bc4deL28tQH8eFr7E+Zom5IkzWqYkeRDgE0GXj8QeGgLzZUjqWodJTksyZIkS1asWDHpciRJ93LDjCT/EbgwydeBAE8D3p3kgcBX56iOa4DtB15v19qYpf23VNXRwNEAixcvrjmqTZK0nlpjSFbVMUlOoTs+CPCXVfWT9vx/zlEdJwGfTvJ+uok7i4Dz6EJ5UZKd6MLxIODlc7RNSZJmNcxIErrdsita/12T7Nom5vRKcjywH7BFkuXAu+gm8nwAWAh8OcmFVfWcqlqa5ETgUmAV8PqBY6BvAE4DFgDHVtXStf2QkiSti2FOAXkP8DJgKXBnay5g1pCsqoN73vpCT/8jgCNmaD8FOGVNdUqSNNeGGUm+EHhEVc2rSTqSJI3aMLNbrwA2HHUhkiTNN8OMJG+jm916JgOnfFTVG0dWlSRJ88AwIXlSe0iStF4Z5hSQj4+jEEmS5pvekExyYlW9NMnFdLNZf0NV7TnSyiRJmrDZRpJvaj8PGEchkiTNN70hWVXXtp9Xj68cSZLmj9l2t97CDLtZp1TVg0dSkSRJ88RsI8kHAST5e+Ba4JN011J9BbD1WKqTJGmChrmYwAuq6sNVdUtV3VxVH8EbH0uS1gPDhOStSV6RZEGS+yV5BXDrqAuTJGnShgnJlwMvBX7WHi/B21VJktYDw1xM4CrcvSpJWg8Nc6usjYHXAnsAG0+1V9VrRliXJEkTN8zu1k8CDwOeA5wFbAfcMsqiJEmaD4YJyV2r6h3Are06rs8HnjDasiRJmrxhQvKO9vPGJI8CNgW2HF1JkiTND8PcKuvoJA8B3kF3y6xNgHeOtCpJkuaBYWa3fqw9PQvYebTlSJI0f6xxd2uSrZIck+TU9nr3JK8dfWmSJE3WMMckjwNOA7Zpry8H3jyqgiRJmi+GCcktqupE4E6AqloFrB5pVZIkzQPDXrt1c9pts5LsC9w00qokSZoHhpnd+la6Wa27JPkGsBB48UirkiRpHhhmdusFSZ4OPILufpKXAfuMurBx+tv/XMo3f3Q9G94vky5F0hhtvdkD2O8Rnvatfr0hmWQB3d0/tgVOraqlSQ4AjgYeADx2PCVKkjQZs40kjwG2B84DPpDkJ8DjgLdX1RfHUdy4vOv39+Drl13H5g/caNKlSBqj629dOekSNM/NFpKLgT2r6s52J5CfArtU1fXjKU2SpMmabXbrr6tq6rSPXwFXGJCSpPXJbCPJRya5qD0P3ezWi9rzqqo9R16dJEkTNFtI/u7YqpAkaR7qDcmqunqchUiSNN8Mc8UdSZLWS4akJEk9ekMyycIku8/QvnuShaMtS5KkyZttJPkBYIsZ2jcH/s9oypEkaf6YLSR3raqzpzdW1TmAp39Iku7zZgvJB83y3oZrWnGSY5Ncl+SSgbaHJjkjyQ/bz4e09v2S3JTkwvZ458Ay+ye5LMmyJIcP86EkSZoLs4XksiTPm96Y5LnAFUOs+zhg/2lthwNnVtUi4Mz2eso5VbVXe/xd29YC4EPAc4HdgYNnOk4qSdIozHYxgTcDX07yUuA7rW0x8ETggDWtuKrOTrLjtOYDgf3a848DXwf+YpbV7AMsq6orAJKc0NZx6Zq2L0nSPdU7kqyqHwKPBs4CdmyPs+guen75Om5vq6q6tj3/KbDVwHtPTPK9JKcm2aO1bQv8eKDP8tY2oySHJVmSZMmKFSvWsURJkjqz3nS5qlYm+QIwdVzx8nax83usqipJtZcXAA+vql+2XbxfBBatwzqPprvfJYsXL641dJckaVaznSe5UZLjgCuBfwH+FbiqTci5/zpu72dJtm7r3xq4DqCqbq6qX7bnpwAbJtkCuIbunpZTtmttkiSN3GwTd/6KbhbrDlW1d1XtBexAN/p8xzpu7yTgkPb8EOBLAEkeliTt+T6truuB84FFSXZqwXxQW4ckSSM32+7WFwH7VNVtUw1VdUuSPwHOZQ1BmeR4ukk6WyRZDrwLOBI4MclrgauBl7buLwb+OMkq4HbgoKoqYFWSNwCnAQuAY6tq6dp/TEnSXGoDm0zdd3iG9xdU1eoxlzXnZhtJ3jkYkFPabtE1Hu+rqoOrauuq2rCqtquqY6rq+qp6ZlUtqqpnVdUNre8Hq2qPqnpMVe1bVd8cWM8pVbVbVe1SVUesy4eUpPuaJA9M8uU24fGSJC9r7Y9LclaS7yQ5beAQ19eTvCfJeUkuT/LU1r5Ha7swyUVJFrX2t7b1XpLkza1tx3be+ifo5qpsP62mq9o2LgBekuTZSb6V5IIk/5Fkk9bvyCSXtu39U2s7LslH2+TLy5Mc0No3TvJvSS5O8t0kz2jthyb5fJKvtHPv/7G1L2jruqQt85bWvkvr+50k5yR55DDf82wjyWon+2eG92b8l4MkrY92PPzL/wzsNcervfCqI5//5lne3x/4SVU9HyDJpkk2pLuk6IFVtaIF5xHAa9oyG1TVPm2C5LuAZwGvA/5PVX2qHdZakORxwKuBJ9BlwLeTnAX8gm5S5SFVdW5PXddX1d5tXsnngWdV1a1J/gJ4a5IPAX8APLJN4NxsYNkd6U792wX4WpJdgdfTzfV8dAu205Ps1vrvBTwWWAlcluQDwJbAtlX1qPa9TK3/aOB1VfXDJE8APgz8t1m+3+4Lm+W9TenOj5wpJCVJk3Ux8L4k7wFOrqpzkjwKeBRwRpvmsQC4dmCZz7ef36ELJIBvAX+VZDvg8y1EngJ8oapuBUjyeeCpdHNCrp4lIAE+037uS3cRmG+0Wu7ftnUT8CvgmCQnAycPLHti2337wyRXAI8EnkIX/FTVD5JcDUyF5JlVdVOr8VLg4cBSYOcWmF+mC9VNgCcB/9FqAdhols9wl9luurzjMCuQpPXdGkZ8I1FVlyfZG3ge8A9JzgS+ACytqif2LLay/VxN+/tfVZ9O8m3g+cApSf5oDZu+dcj3A5xRVQdP79AmaD6Tbj7KG7h7RDf9UN6aDu2tHHi+mm6k/IskjwGeQzdKfindxXFubBNQ18pa3U+y7dN9RxInz0jSBCXZBritqv4deC+wN3AZsDDJE1ufDXP3xVn61rMzcEVVHUV3xsGewDnAC5P8TpIH0u0ePWctSzwXeHLbZTp1DHW3NqrbtJ3u9xbgMQPLvCTJ/ZLsAuzcPs85wCvaOnajO8vislk+zxbA/arqc8BfA3tX1c3AlUle0vqkBekazXoxgbaybYCXAS+nuwLP/6I7FUOSNDmPBt6b5E7gDuCPq+rXSV4MHJVkU7q/8f9Mtwuyz0uBVya5g+5KaO+uqhvSnSd/Xuvzsar6bn77UqO92jHRQ4Hjk0zt2vxr4BbgS0k2phttvnVgsf9q23ww3fHDXyX5MPCRJBcDq4BD24Vu+ja9LfBvSaYGgW9vP1/R1vPXdKc3ngB8b02fI92ZFjO8kRwGHNw2eGJ7fKmqdlrTSueDxYsX15IlS4bu//XLrmPzBw61i1rSfcT1t65kv0dsubaLOU9jBFoon1xVn510LYNmG0l+kO4g68uraglA7r6MnCRJ93mzheTWwEvoZk89jG4kucb7SEqStLaq6tBJ1zCT2e4Ccn1VfbSqnk43C+lGumuvfj/Ju8dWoSRJEzLU7NaqWl5V76uqxXT3c5yTO4FIkjSfrXF263TtXpJ/N4JaJEmaV9bqPElJktYns4ZkO+Fy+9n6SJJ0XzVrSLbbVZ0yplokSZpXhtndekGSx4+8EkmS5plhJu48AXhFu/L6rXRXm6iq2nOklUmSNGHDhORzRl6FJEnz0Bp3t1bV1cBmwO+3x2atTZKk+7Q1hmSSNwGforvb85bAvyf501EXJknSpA2zu/W1wBMG7lD9HroLn39glIVJkjRpw8xuDd0dn6esxlvFSJLWA8OMJP8N+HaSL9CF44HAMSOtSpKkeWCNIVlV70/ydeAprenVVfXdkVYlSdI8sMaQTLILsLSqLkjyDOCpSa6sqhtHX54kSZMzzDHJzwGrk+wKfBTYHvj0SKuSJGkeGCYk76yqVcCLgA9W1f8Eth5tWZIkTd4wIXlHkoOBVwEnt7YNR1eSJEnzwzAh+WrgicARVXVlkp2AT462LEmSJm+Y2a2XAm8ceH0l8J5RFiVJ0nwwzOzWJwN/Azy89Z+6C8jOoy1NkqTJGuZiAscAbwG+w29eeUeSpPu0YULypqo6deSVSJI0zwwTkl9L8l7g88DKqcaqumBkVUmSNA8ME5JPaD8XD7QV8N/mvhxJkuaPYWa3PmMchUiSNN8Mc9PlrZIck+TU9nr3JK8dfWmSJE3WMBcTOA44Ddimvb4cePOoCpIkab4YJiS3qKoTgTsB2nVchzoVJMmxSa5LcslA20OTnJHkh+3nQ1p7khyVZFmSi5LsPbDMIa3/D5McslafUJKkdTRMSN6aZHO6yTok2Re4acj1HwfsP63tcODMqloEnNleAzwXWNQehwEfadt7KPAuuglE+wDvmgpWSZJGaZiQfCtwErBLkm8AnwD+dJiVV9XZwA3Tmg8EPt6efxx44UD7J6pzLrBZkq2B5wBnVNUNVfUL4Ax+O3glSZpzw8xuvSDJ04FH0F2S7rKquuMebHOrqrq2Pf8psFV7vi3w44F+y1tbX7skSSPVO5JM8vgkD4O7jkM+DjgCeF/bBXqPVVXRduPOhSSHJVmSZMmKFSvmarWSpPXUbLtb/wX4NUCSpwFH0u1qvQk4+h5s82dtNyrt53Wt/Rpg+4F+27W2vvbfUlVHV9Xiqlq8cOHCe1CiJEmzh+SCqpo6nvgy4Oiq+lxVvQPY9R5s8yRgaobqIcCXBtpf1Wa57kt3zdhr6U4/eXaSh7QJO89ubZIkjdRsxyQXJNmg7Wp9Jt2M02GWu0uS44H9gC2SLKebpXokcGK7IMHVwEtb91OA5wHLgNvobvZMVd2Q5O+B81u/vxsIb0mSRma2sDseOCvJz4HbgXMAkuzKkKeAVNXBPW89c4a+Bby+Zz3HAscOs01JkuZKb0hW1RFJzgS2Bk5vIQbdLtqhTgGRJOnebNbdpu18xeltl4+uHEmS5o9hLiYgSdJ6yZCUJKmHISlJUg9DUpKkHoakJEk9DElJknoYkpIk9TAkJUnqYUhKktTDkJQkqYchKUlSD0NSkqQehqQkST0MSUmSehiSkiT1MCQlSephSEqS1MOQlCSphyEpSVIPQ1KSpB6GpCRJPQxJSZJ6GJKSJPUwJCVJ6mFISpLUw5CUJKmHISlJUg9DUpKkHoakJEk9DElJknoYkpIk9TAkJUnqYUhKktTDkJQkqYchKUlSD0NSkqQeEwnJJG9KckmSpUne3Nr+Jsk1SS5sj+cN9H97kmVJLkvynEnULEla/2ww7g0meRTwh8A+wK+BryQ5ub39v6vqn6b13x04CNgD2Ab4apLdqmr1GMuWJK2HJjGS/F3g21V1W1WtAs4CXjRL/wOBE6pqZVVdCSyjC1hJkkZqEiF5CfDUJJsn+R3gecD27b03JLkoybFJHtLatgV+PLD88tb2W5IclmRJkiUrVqwYVf2SpPXE2EOyqr4PvAc4HfgKcCGwGvgIsAuwF3At8L51WPfRVbW4qhYvXLhw7oqWJK2XJjJxp6qOqarHVdXTgF8Al1fVz6pqdVXdCfwrd+9SvYa7R5oA27U2SZJGalKzW7dsP3egOx756SRbD3T5A7rdsgAnAQcl2SjJTsAi4Lxx1itJWj+NfXZr87kkmwN3AK+vqhuTfCDJXkABVwF/BFBVS5OcCFwKrGr9ndkqSRq5iYRkVT11hrZXztL/COCIkRYlSdI0XnFHkqQehqQkST0MSUmSehiSkiT1MCQlSephSEqS1MOQlCSphyEpSVIPQ1KSpB6GpCRJPQxJSZJ6GJKSJPUwJCVJ6mFISpLUw5CUJKmHISlJUg9DUpKkHoakJEk9DElJknoYkpIk9TAkJUnqYUhKktTDkJQkqYchKUlSD0NSkqQehqQkST0MSUmSehiSkiT1MCQlSephSEqS1MOQlCSphyEpSVIPQ1KSpB6GpCRJPQxJSZJ6GJKSJPUwJCVJ6mFISpLUYyIhmeRNSS5JsjTJm1vbQ5OckeSH7edDWnuSHJVkWZKLkuw9iZolSeufsYdkkkcBfwjsAzwGOCDJrsDhwJlVtQg4s70GeC6wqD0OAz4y7polSeunSYwkfxf4dlXdVlWrgLOAFwEHAh9vfT4OvLA9PxD4RHXOBTZLsvW4i5YkrX82mMA2LwGOSLI5cDvwPGAJsFVVXdv6/BTYqj3fFvjxwPLLW9u1TJPkMLrRJjvssMNaFbXJRhtw/a0r12oZSfdum2w0iT+BujcZ+/8hVfX9JO8BTgduBS4EVk/rU0lqHdZ9NHA0wOLFi9dq+cU7PnRtNydJuo+byMSdqjqmqh5XVU8DfgFcDvxsajdq+3ld634NsP3A4tu1NkmSRmpSs1u3bD93oDse+WngJOCQ1uUQ4Evt+UnAq9os132BmwZ2y0qSNDKT2iH/uXZM8g7g9VV1Y5IjgROTvBa4Gnhp63sK3XHLZcBtwKsnUbAkaf0zkZCsqqfO0HY98MwZ2gt4/TjqkiRpkFfckSSphyEpSVIPQ1KSpB6GpCRJPQxJSZJ6GJKSJPUwJCVJ6mFISpLUI925+vc9SVbQXblnWFsAPx9ROetqvtVkPbObb/XA/KvpvlDPz6tq/1EUo/nnPhuSayvJkqpaPOk6Bs23mqxndvOtHph/NVmP7m3c3SpJUg9DUpKkHobk3Y6edAEzmG81Wc/s5ls9MP9qsh7dq3hMUpKkHo4kJUnqYUhKktRjvQvJJPsnuSzJsiSHz/D+Rkk+097/dpIdJ1zPoUlWJLmwPf7HiOs5Nsl1SS7peT9Jjmr1XpRk7wnXs1+Smwa+n3eOuJ7tk3wtyaVJliZ50wx9xvYdDVnPuL+jjZOcl+R7raa/naHP2H7PhqxnrL9nuhepqvXmASwAfgTsDNwf+B6w+7Q+fwJ8tD0/CPjMhOs5FPjgGL+jpwF7A5f0vP884FQgwL7Atydcz37AyWP8frYG9m7PHwRcPsN/s7F9R0PWM+7vKMAm7fmGwLeBfaf1Gefv2TD1jPX3zMe957G+jST3AZZV1RVV9WvgBODAaX0OBD7enn8WeGaSTLCesaqqs4EbZulyIPCJ6pwLbJZk6wnWM1ZVdW1VXdCe3wJ8H9h2WrexfUdD1jNW7XP/sr3csD2mzxAc2+/ZkPVIM1rfQnJb4McDr5fz239Q7upTVauAm4DNJ1gPwP/Xdtt9Nsn2I6plWMPWPE5PbLvSTk2yx7g22nYRPpZuZDJoIt/RLPXAmL+jJAuSXAhcB5xRVb3f0Rh+z4apB+bX75nmifUtJO+N/hPYsar2BM7g7n99q3MB8PCqegzwAeCL49hokk2AzwFvrqqbx5MrwmkAAAWjSURBVLHNe1DP2L+jqlpdVXsB2wH7JHnUqLd5D+vx90wzWt9C8hpg8F+I27W2Gfsk2QDYFLh+UvVU1fVVtbK9/BjwuBHVMqxhvsOxqaqbp3alVdUpwIZJthjlNpNsSBdIn6qqz8/QZazf0ZrqmcR3NLDtG4GvAdMvCD7O37M11jMPf880T6xvIXk+sCjJTknuTzdh4KRpfU4CDmnPXwz8/1U1quMXa6xn2rGsF9Adc5qkk4BXtRmc+wI3VdW1kyomycOmjmUl2Yfu/+mR/bFt2zoG+H5Vvb+n29i+o2HqmcB3tDDJZu35A4DfA34wrdvYfs+GqWce/p5pnthg0gWMU1WtSvIG4DS6maXHVtXSJH8HLKmqk+j+4HwyyTK6CSMHTbieNyZ5AbCq1XPoqOoBSHI83WzILZIsB95FN9GBqvoocArd7M1lwG3Aqydcz4uBP06yCrgdOGiE/6gBeDLwSuDidowL4C+BHQZqGud3NEw94/6OtgY+nmQBXSCfWFUnT+r3bMh6xvp7pnsPL0snSVKP9W13qyRJQzMkJUnqYUhKktTDkJQkqYchKUlSD0NSI5VkdburwtJ2WbQ/S3K/9t7iJEfNsuyOSV4+vmp/a/sPSHJWO3VgXZZ/QdqdXZK8MMnua+j/uvY9XZ7kb1rbwiRfWZftS7rnDEmN2u1VtVdV7UF3Evdz6c51pKqWVNUbZ1l2R2BiIQm8Bvh8Va1el4Wr6qSqOrK9fCEwa0jSnVf5WODRwCFJtquqFcC1SZ68LjVIumcMSY1NVV0HHAa8oV2NZr8kJwMkefrAvfy+m+RBwJHAU1vbW9rI8pwkF7THk9qy+yX5ersw9Q+SfGrgCjOPT/LNNoo9L8mD0l3s+r1Jzk93Qes/6in5FcCXBrZx8tQbST6Y5ND2/Kokf9tqujjJI1v7oa3fk+iu4vLe9ll2SfLGdPeAvCjJCe37+Wq7G0zoLvTx67a5L7ZaJI3ZenXFHU1eVV3Rdl9uOe2ttwGvr6pvpLtY96+Aw4G3VdUBAEl+B/i9qvpVkkXA8cDitvxjgT2AnwDfAJ6c5DzgM8DLqur8JA+mu+LMa+kuFff4JBsB30hyelVdOVVMussE7lxVVw350X5eVXsn+ZP2We66aW9VfTPJSXT3dPxsW//hwE5VtXLqkmkDjgZOaP+oAFgC/MOQdUiaQ44kNV98A3h/kjcCm7XbJ023IfCvSS4G/oPf3H15XlUtr6o7gQvpdtU+Ari2qs6Huy70vQp4Nt21VS+ku63U5sCiadvaArhxLeqfurD4d9q21+Qi4FNJ/jvdpdCA7jgm3WXU/mKg73XANmtRi6Q5YkhqrJLsDKym+8N/l3bs7n8AD6Ab2T1yhsXfAvwMeAzdCPL+A++tHHi+mtn3kgT403asdK+q2qmqTp/W53Zg44HXq/jN35eNf7P7Xdtf07anPB/4ELA3cH66O2EA7Amc3sJ+cFu3D7FOSXPMkNTYJFkIfBT44PQLbCfZpaourqr30N0d5ZHALcCDBrptSjcyvJPuot5rmnV6GbB1kse3bTyohdFpdBf83rC175bkgYMLVtUvgAVJpsLwamD3JBu13aPPXMuPf9dnabN7t6+qr9GNGDcFNmn9vshv35lmN+CStdyepDngMUmN2gPabs0N6UZjnwRmuqXTm5M8A7gTWAqc2p6vTvI94Djgw8DnkrwK+Apw62wbrqpfJ3kZ8IF0t0i6HXgW3f0CdwQuaBN8VtDNPp3udOApwFer6sdJTqQLqyuB7w79DXROoNtV/Ea6O14ck2RTulHtUe0+h7Tt3UYX8FOeAXx5LbcnaQ54FxCpR5K9gbdU1SsnXMfZwIFtdCtpjNzdKvWoqguAr63rxQTmQttF/X4DUpoMR5KSJPVwJClJUg9DUpKkHoakJEk9DElJknoYkpIk9fh/UJNyrH7sD9EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 477.5x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE51b9jTA9BC"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVpp6tyQAt6k"
      },
      "source": [
        "# Obstacle Avoidance Behaviour\n",
        "\n",
        "When developing Obstacle Avoidance behaviour, it is recommended to put aside any previous line following behaviour.  It is better to simplify the problem first.  Once obstacle avoidance is achieved, the complexity of the problem can be increased to include line following behaviour.  \n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"50%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_ObsAvoid.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "For obstacle avoidance behaviour, it is necessary for the robot to decide:\n",
        "- is there an obstruction?\n",
        "  - a logical choice, similar to the bang-bang controller operation.\n",
        "- how to utilise the 8 sensors?\n",
        "  - a more complex issue, where a form of weighted-measurement might be useful.\n",
        "\n",
        "In Labsheet 2 we implemented a `weighted-measurement` for line following.  This was expressed as the equations:\n",
        "\n",
        "<p align=\"center\">\n",
        "$w_{left} = ( gs_{0} + ( gs_{1} * 0.5 ) )$\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "$w_{right} = ( gs_{2} + ( gs_{1} * 0.5 ) )$\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "$e_{line} = w_{left} - w_{right}$\n",
        "</p>\n",
        "\n",
        "where `gs0`, `gs1`, and `gs2` correspond to the left, centre and right sensing elements of the ground sensor.  In the above equations, we can see that the value of `gs1` is weighted by 0.5.  \n",
        "\n",
        "As a matter of interest, we can also reconceptualise this technique with an illustration of the form of a very simple <a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\">artificial neural network</a>, where each node in the network transferring forward a summation weighted inputs:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"50%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_LineANN.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "In the above illustration, the value from each node is fed forwards, as indicated by the arrows.  So in the first row of nodes (\"input layer\"), the nodes labelled `gs0`, `gs1`, `gs21` receive the latest value of the ground sensors.  The small numbers next to the arrows represent `weights`.  When a weight has magnitude `1.0`, the value passed forwards is unmodified.  When a weight has magnitude `0.0`, this would effectively negate the propogation of the input to the next connected node.  Each node in the network operates a simple summation of all the inputs received as a `transfer function`.\n",
        "\n",
        "This representation of weighting inputs to produce a useful output is particularly useful for designing obstacle avoidance.  In the case of the e-puck robot, there are 8 infra-red proximity sensors, and we must decide how they can be used to effect obstacle avoidance behaviour. \n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"75%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_ObsANN.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "In the above illustration, it is necessary to decide which sensors (`ps0` to `ps7`) will be fed forwards to the output node, $e_{obs}$ (error - obstruction), and with what weighting.  Here, we are assuming a similar principle of operation to our prior work in Labsheet 2 Line Sensing, where $e_{obs}$ would be an error signal used to then inform the operation of both left and right motors.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/cyberbotics/webots/released/docs/guide/images/robots/epuck/sensors_and_leds.png\">\n",
        "</p>\n",
        "\n",
        "If we consider the above body-plan of the e-puck robot, we can see that `ps7` and `ps0` face directly forwards.  We can imagine that encountering an obstruction on these sensors would cause a rapid turn.  Furthermore, for `ps7`, the robot might need to turn right, and for `ps0` the robot might need to turn left.  \n",
        "\n",
        "\n",
        "Within Webots, we can access the e-puck proximity sensors with the following example code extract:\n",
        "\n",
        "```c\n",
        "\n",
        "  // Loop through all proximity sensors [0:7]\n",
        "  int i;\n",
        "  for( i = 0; i < NB_PS; i++ ) {\n",
        "\n",
        "    // read value from sensor\n",
        "    ps_value[i] =  wb_distance_sensor_get_value(ps[i]);\n",
        "    \n",
        "    // Print this value to the console to inspect.\n",
        "    printf(\"%f,\", ps_value[i]);\n",
        "  }\n",
        "  printf(\"\\n\");\n",
        "```\n",
        "\n",
        "The following code extract illustrates how `weights` could be used to generate an output signal, $e_{obs}$:\n",
        "\n",
        "```c\n",
        "int i;\n",
        "// Same number of weigths as sensors\n",
        "float weights[NB_PS] = { 0.1, 0.2, 0.4, 0.5, -0.5, -0.4, -0.2, -0.1 };\n",
        "float e_obs;\n",
        "\n",
        "// Set initial value.\n",
        "e_obs = 0.0;\n",
        "for( i = 0; i < NB_PS; i++ ) {\n",
        "\n",
        "    // read value from sensor\n",
        "    ps_value[i] =  wb_distance_sensor_get_value(ps[i]);\n",
        "\n",
        "    // Simple summation of weighted sensor values.\n",
        "    e_obs = e_obs + ( ps_value[i] * weights[i] );\n",
        "\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "It is possible to configure a variety of connections between the sensors and some output node(s).  It is also possible to design a very simple ANN to utilise two output nodes, one to control the left motor speed and one to control the right motor speed:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"50%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_ObsANN_2.png?raw=true\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTAQHl69vNL9"
      },
      "source": [
        "## Exercise 2: Obstacle Avoidance\n",
        "\n",
        "Depending on your implementation you could either:\n",
        " - have obstacle avoidance always active, but not not always contributing to motion (e.g., in the ANN implementation above, it is possible to have a configuration of the network that provides 0 contribution when no sensors are active).\n",
        " - have obstacle avoidance activated only when necessary.  In this method, you would need to add a simple check on your proximity sensors to decide whether obstacle avoidance is necessary.\n",
        "\n",
        "\n",
        "1. Before you start writing code consider:\n",
        "  - how could obstacle avoidance behaviour be achieved with a bang-bang controller?\n",
        "  - what advantages or disadvantages might there to a bang-bang controller?\n",
        " \n",
        "2. Decide a threshold value from the `sensor response curve` for when an `obstacle avoidance behaviour` should be activated.  \n",
        "  - **Note:** the proximity sensors always report a value, even when there is not an obstruction. \n",
        "  - write a function to check all proximity sensors and return an appropriate value if obstacle avoidance is required.\n",
        "  - check that this function operates reliably.\n",
        "  - utilise the result of this function to either:\n",
        "    - transition your FSM into/out-of obstacle avoidance appropriately (preferred)\n",
        "    - activate obstacle avoidance execution flow in your program\n",
        "\n",
        "3. Start by creating a weight of 0 for all sensors.  With just the two foward proximity sensors, find weight values to effect a turning behaviour in the approriate direction:\n",
        "  - which two proximity senors are the most forward facing?\n",
        "  - how might you pre-process your proximity sensor measurements to make subsequent calculations easier?\n",
        "  - **help:** to begin with, do not have your robot move forward or backward, only turn on the spot.  \n",
        "  - **help:** remember that you can position your robot within the environment by clicking on it.\n",
        "  - **help:** avoid **`blocking code`** - for exmaple, your obstacle avoidance function should return and be called again by `loop()` even while there is an obstruction.\n",
        "  - what would be a desirable value of `e_obs` if both forward sensors report identical values, or cancel each other out?  Implement a bias in your gain values to solve this issue.  \n",
        "    - **Hypothesise:** in what environment circumstances would the robot be in where both sensors report the same value?\n",
        "  - **Validate:** using just the two forward sensors, how far does your robot rotate away from the obstruction?  Would this enough to transit without collision?\n",
        "  - **help**: the following code extract follows a similar format to line following:\n",
        "\n",
        "\n",
        "  ```c\n",
        "\n",
        "void loop() {\n",
        "\n",
        "  \n",
        "\n",
        "  // Get the line error\n",
        "  float e_obs;\n",
        "  e_obs = getObstacleError();\n",
        "\n",
        "  // Determine a proportional rotation speed\n",
        "  float turn_velocity;\n",
        "  turn_velocity = ????;  // What is a sensible maximum speed?\n",
        "  turn_velocty = turn_velocity * e_obs;\n",
        "\n",
        "  // Set motor values.\n",
        "  // What does \"0 -\" and \"0 +\" achieve here?\n",
        "  wb_motor_set_velocity(right_motor, 0 - turn_velocity);\n",
        "  wb_motor_set_velocity(left_motor, 0 + turn_velocity);\n",
        "  \n",
        "}\n",
        "\n",
        "// A function to return an error signal representative\n",
        "// of the line placement under the ground sensor.\n",
        "float getObstacleError() {\n",
        "  float weights[NB_PS] = { 0.1, 0.2, 0.4, 0.5, -0.5, -0.4, -0.2, -0.1 };\n",
        "  float e_obs;\n",
        "\n",
        "  // Read proximity sensors, store result\n",
        "\n",
        "  // Calculated error signal\n",
        "  e_obs = ????;\n",
        "\n",
        "  // Return result\n",
        "  return e_obs;\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "3. Progressively implement the remaining proximity sensors into your obstacle avoidance function:\n",
        "  - are all sensors necessary?\n",
        "  - two sensors are at the rear of the robot, are these useful?\n",
        "\n",
        "4. Implement a forward velocity for your obstacle avoidance:\n",
        "  - consider if this can be `proportionally controlled`, and whether this is useful.  What would be a useful measurement for forward velocity control?\n",
        "  - when would a backward velocity useful?\n",
        "\n",
        "5. How might you calculate a measure of obstacle avoidance performance?\n",
        "  - what `proprioceptive` information is available to the robot?\n",
        "  - what `exteroceptive` information is available to the robot?\n",
        "  - what features of the robot behaviour are more or less desirable, and how could these be represented mathematically within this `metric` of performance?\n",
        "  - how could this `metric` be defined and calculated to make it as transferable (comparable) as possible between different robotic systems?\n",
        "  - **help**: in machine learning, we might consider this the <a href=\"https://en.wikipedia.org/wiki/Reinforcement_learning\">reward function</a> or the <a href=\"https://en.wikipedia.org/wiki/Evolutionary_algorithm\">fitness function</a>.  \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4JUDNmybu1x"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EqsZDsqI_Qe"
      },
      "source": [
        "## Exercise 3: Obstacle Tracking\n",
        "\n",
        "In this exercise we will investigate a method to process the proximity sensors on the robot to be more intuitive to use.  Currently, the sensors have a non-linear response.  In this exercise, we will look at signal conditioning to make the sensor response linear.  \n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"75%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_ObsTracking.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "Within the Line Following Challenge it is necessary that your robot can avoid the obstruction on the line but continue to follow the line afterwards.  To produce this behaviour it is necessary that your robot does not simply avoid the obstacle, but circumnavigates the perimeter of the obstacle.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"75%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_ObsConditioning.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "We can review the plot of the sensor response you have produced earlier in the labsheet.  The above plot is from the Webots documentation, your's should look similar.  When we consider the response of the sensor, we can identy three important characteristics:\n",
        "\n",
        "- In the above, the red area represents when the robot is getting **too close** to an obstruction, and would need to make an avoidance motion.  \n",
        "- In the above, the green area represents when the robot is **moving away** from the obstruction.  To keep the obstruction within the sensor detection, this range of the sensor could be used to provide an attraction motion towards the obstruction.\n",
        "- Between these two ranges is an **ideal** distance, which needs to be determined to stop the robot from colliding with an obstruction, but not losing the obstruction.  \n",
        "\n",
        "Using the idea of signal conditioning and a normalised value, we can represent the above intended responses in the range [-1.0 : +1.0 ], where `-1` would influence a maximally avoidant motion, and `+1` a maximally attractive motion.  Importantly, values less than `-1` or more than `+1` represent values we are not confident in, and so discard.  \n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"50%\" src=\"https://github.com/paulodowd/EMATM0053_21_22/blob/main/images/Webots_ProxProcessed.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "We can consider this normalisation per sensor with respect to the robot, as illustrated above.\n",
        "\n",
        "\n",
        "When we review the above plot, it has also been annotated in blue with the minimum and maximum of the sensor reading we are interested in, and the mid-point.  It is important to see that for a linear mapping, the mid-point of the range does not match the mid-point of our desired normalisation (a value of 0).  This is because the sensor has a non-linear reponse.\n",
        "\n",
        "We can either make the normalisation a non-linear mapping, or we can first of all convert the sensor reading into a linear mapping of distance.  In these exercises, we decide to convert the sensor reading values into a linear mapping of distance:\n",
        "\n",
        "1. Using the proximity sensor data with respect to distance that you have collected earlier, find an equation for a trend-line of best fit.  For the Webot e-puck proximity sensor, a simple power regression should be sufficient.\n",
        "  - **Help:** If you are not sure how to do this, a quick method is to plot your data in Microsoft Excel, use the trendline function and enable the `display equation on chart` option.\n",
        "  - **Help:** A power regression has the form:\n",
        "\n",
        "> $ y = ax^{\\beta}$\n",
        "\n",
        "Here, $y$ is our sensor reading, and $x$ is the distance.  This equation can be re-arranged for $x$:\n",
        "\n",
        "> $x = (y / a ) ^{1/\\beta}$\n",
        "\n",
        "2. Write a short function in your code to receive a sensor reading and return a distance value.\n",
        "  - **Validate**: check that your robot returns an estimate of distance from an obstruction by setting up the simulator environment and reporting values to the console.\n",
        "\n",
        "3. Determine an equation to take any distance estimate from a proximity sensor reading and normalise it between the values [ -1.0 : +1.0 ].   You will need to:\n",
        "  - decide which distance values are the minimum and maximum points for your range.\n",
        "  - calculate the total range of an expected reading from the sensor\n",
        "  - include any offset of the total range of expected readings from zero\n",
        "  - include an offset to center the normalisation (0) and provide -1.0/+1.0 output.\n",
        "  - use this equation to create a new function in your code that will return this sensor reading normalisation.\n",
        "\n",
        "4. **Validate:** Check that your normalisation is working as you'd expect.  Keep things simple to begin with.  Write some test code to report the normalised value under **controlled** conditions.  Keep your robot still, and experiment with the proximity of an obstruction.  \n",
        "  - Check that your sensor reports a range [ -1.0 : +1.0 ].\n",
        "  - At what distance does the normalisation report a 0 value?\n",
        "\n",
        "5. **Validate:** Begin to integrate this new information into your obstacle avoiance controller.  Keep things simple to being with.  First of all, use the forward facing sensors and see if you can adjust your obstacle avoidance code so that your robot will move towards the obstruction but stop at the normalised value of 0.\n",
        "\n",
        "6. **Validate:** Experiment with your obstacle avoidance controller across all sensors.  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R505QizBBnb"
      },
      "source": [
        "<hr><br><br><br><br>"
      ]
    }
  ]
}